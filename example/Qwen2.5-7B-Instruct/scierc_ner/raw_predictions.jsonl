{"doc_id": 0, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination. The problem is formulated in a manner that subsumes structure from motion, multi-view stereo, and photo-metric stereo as special cases. The algorithm utilizes both spatial and temporal intensity variation as cues: the former constrains flow and the latter constrains surface orientation; combining both cues enables dense reconstruction of both textured and texture-less surfaces. The algorithm works by iteratively estimating affine camera parameters, illumination, shape, and albedo in an alternating fashion. Results are demonstrated on videos of hand-held objects moving in front of a fixed light and camera.", "output": "{\"Generic\": [\"latter\", \"former\", \"algorithm\"], \"Material\": [\"videos of hand-held objects\", \"multi-view stereo\", \"image sequence\", \"photo-metric stereo\", \"motion\", \"rigidly-moving Lambertian object\"], \"Method\": [\"estimating affine camera parameters , illumination , shape , and albedo\"], \"Metric\": [], \"OtherScientificTerm\": [\"spatial and temporal intensity variation\", \"distant illumination\", \"flow\", \"surface orientation\"], \"Task\": [\"computing optical flow , shape , motion , lighting , and albedo\", \"dense reconstruction of both textured and texture-less surfaces\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:0"}, "target": "{\"Generic\": [\"latter\", \"former\", \"algorithm\"], \"Material\": [\"videos of hand-held objects\", \"multi-view stereo\", \"image sequence\", \"photo-metric stereo\", \"motion\", \"rigidly-moving Lambertian object\"], \"Method\": [\"estimating affine camera parameters , illumination , shape , and albedo\"], \"Metric\": [], \"OtherScientificTerm\": [\"spatial and temporal intensity variation\", \"distant illumination\", \"flow\", \"surface orientation\"], \"Task\": [\"computing optical flow , shape , motion , lighting , and albedo\", \"dense reconstruction of both textured and texture-less surfaces\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper presents an algorithm for computing optical flow, shape, motion, lighting, and albedo from an image sequence of a rigidly-moving Lambertian object under distant illumination. The problem is formulated in a manner that subsumes structure from motion, multi-view stereo, and photo-metric stereo as special cases. The algorithm utilizes both spatial and temporal intensity variation as cues: the former constrains flow and the latter constrains surface orientation; combining both cues enables dense reconstruction of both textured and texture-less surfaces. The algorithm works by iteratively estimating affine camera parameters, illumination, shape, and albedo in an alternating fashion. Results are demonstrated on videos of hand-held objects moving in front of a fixed light and camera.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"computing optical flow\", \"shape\", \"motion\", \"lighting\", \"albedo\", \"dense reconstruction\"], \"Method\": [\"algorithm\", \"iteratively estimating affine camera parameters\", \"illumination\", \"shape\", \"albedo\"], \"Material\": [\"image sequence\", \"rigidly-moving Lambertian object\", \"distant illumination\", \"videos of hand-held objects moving in front of a fixed light and camera\"], \"OtherScientificTerm\": [\"Lambertian object\", \"structure from motion\", \"multi-view stereo\", \"photo-metric stereo\", \"texture-less surfaces\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"computing optical flow\", \"shape\", \"motion\", \"lighting\", \"albedo\", \"dense reconstruction\"], \"Method\": [\"algorithm\", \"iteratively estimating affine camera parameters\", \"illumination\", \"shape\", \"albedo\"], \"Material\": [\"image sequence\", \"rigidly-moving Lambertian object\", \"distant illumination\", \"videos of hand-held objects moving in front of a fixed light and camera\"], \"OtherScientificTerm\": [\"Lambertian object\", \"structure from motion\", \"multi-view stereo\", \"photo-metric stereo\", \"texture-less surfaces\"], \"Generic\": []}"], "doc_hash": "0d9ca6771fe37ebed8bdf760bd87df982245acb12f7b528c039f00e7490211d0", "prompt_hash": "f28c17c414d64f78ada3ddd181f803384d0ae63407d31ea4065666ff0617e55a", "target_hash": "ed27dae3fcf63b7b0d89c442650f8d46cc616db0cb9cee036151cce17b0f3621", "bypass": null}
{"doc_id": 1, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nPast work of generating referring expressions mainly utilized attributes of objects and binary relations between objects. However, such an approach does not work well when there is no distinctive attribute among objects. To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them. The key is to identify groups of objects that are naturally recognized by humans. We conducted psychological experiments with 42 subjects to collect referring expressions in such situations, and built a generation algorithm based on the results. The evaluation using another 23 subjects showed that the proposed method could effectively generate proper referring expressions.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"generation algorithm\"], \"Metric\": [], \"OtherScientificTerm\": [\"n-ary relations\", \"binary relations\", \"referring expressions\"], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:1"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"generation algorithm\"], \"Metric\": [], \"OtherScientificTerm\": [\"n-ary relations\", \"binary relations\", \"referring expressions\"], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nPast work of generating referring expressions mainly utilized attributes of objects and binary relations between objects. However, such an approach does not work well when there is no distinctive attribute among objects. To overcome this limitation, this paper proposes a method utilizing the perceptual groups of objects and n-ary relations among them. The key is to identify groups of objects that are naturally recognized by humans. We conducted psychological experiments with 42 subjects to collect referring expressions in such situations, and built a generation algorithm based on the results. The evaluation using another 23 subjects showed that the proposed method could effectively generate proper referring expressions.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"generating referring expressions\"], \"Method\": [\"generation algorithm\"], \"Material\": [], \"OtherScientificTerm\": [\"psychological experiments\", \"referring expressions\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"generating referring expressions\"], \"Method\": [\"generation algorithm\"], \"Material\": [], \"OtherScientificTerm\": [\"psychological experiments\", \"referring expressions\"], \"Generic\": []}"], "doc_hash": "bc4a25829c4d2fe90639d78481282f7e75698596d540ec5bdf50f445463aa7c3", "prompt_hash": "69b07192018ac64e6484ac95d726a19678c9b0983f44cb00120ed0e6a8b63e72", "target_hash": "d95083cd0978175ad475ef0d43466226cb566633aad991e3ee4ff3360224c3b8", "bypass": null}
{"doc_id": 2, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe apply a decision tree based approach to pronoun resolution in spoken dialogue. Our system deals with pronouns with NP-and non-NP-antecedents. We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features. We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's (2002) manually tuned system.", "output": "{\"Generic\": [], \"Material\": [\"Switchboard dialogues\"], \"Method\": [\"Byron \\u0027s (2002) manually tuned system\", \"decision tree based approach\"], \"Metric\": [], \"OtherScientificTerm\": [\"features\", \"NP - and non-NP-antecedents\", \"pronouns\"], \"Task\": [\"pronoun resolution\", \"spoken dialogue\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:10"}, "target": "{\"Generic\": [], \"Material\": [\"Switchboard dialogues\"], \"Method\": [\"Byron \\u0027s (2002) manually tuned system\", \"decision tree based approach\"], \"Metric\": [], \"OtherScientificTerm\": [\"features\", \"NP - and non-NP-antecedents\", \"pronouns\"], \"Task\": [\"pronoun resolution\", \"spoken dialogue\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe apply a decision tree based approach to pronoun resolution in spoken dialogue. Our system deals with pronouns with NP-and non-NP-antecedents. We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features. We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron 's (2002) manually tuned system.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"pronoun resolution in spoken dialogue\"], \"Method\": [\"decision tree based approach\", \"a set of features\"], \"Material\": [\"Switchboard dialogues\"], \"OtherScientificTerm\": [\"NP-and non-NP-antecedents\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"pronoun resolution in spoken dialogue\"], \"Method\": [\"decision tree based approach\", \"a set of features\"], \"Material\": [\"Switchboard dialogues\"], \"OtherScientificTerm\": [\"NP-and non-NP-antecedents\"], \"Generic\": []}"], "doc_hash": "65b73951827e2e952a43c99a87843f5db664f7433985225771141f807ea9146d", "prompt_hash": "eb146ccabd20045642f07ce10d453dd809a79033f74e14cee2e4f8a760e81bcd", "target_hash": "35ef6a46537b0d63f60f5f50ff0ff300dd3bf5169b1e3b1d1506d78d01c700e2", "bypass": null}
{"doc_id": 3, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a new approach for building an efficient and robust classifier for the two class problem, that localizes objects that may appear in the image under different orien-tations. In contrast to other works that address this problem using multiple classifiers, each one specialized for a specific orientation, we propose a simple two-step approach with an estimation stage and a classification stage. The estimator yields an initial set of potential object poses that are then validated by the classifier. This methodology allows reducing the time complexity of the algorithm while classification results remain high. The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients (HOGs), which we compute during a pre-processing step. Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time. We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations, and with challenging conditions such as cluttered backgrounds, changing illumination conditions and partial occlusions.", "output": "{\"Generic\": [\"conditions\", \"database\", \"approach\"], \"Material\": [\"image\", \"motorbikes under planar rotations\"], \"Method\": [\"classifiers\", \"classification stage\", \"boosted combination of Random Ferns\", \"estimation stage\", \"pre-processing step\", \"supervised learning\"], \"Metric\": [\"time complexity\"], \"OtherScientificTerm\": [\"object poses\", \"changing illumination conditions\", \"partial occlusions\", \"gradient space\", \"cluttered backgrounds\", \"local histograms of oriented gradients (HOGs)\", \"orien-tations\"], \"Task\": [\"class problem\", \"classification\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:11"}, "target": "{\"Generic\": [\"conditions\", \"database\", \"approach\"], \"Material\": [\"image\", \"motorbikes under planar rotations\"], \"Method\": [\"classifiers\", \"classification stage\", \"boosted combination of Random Ferns\", \"estimation stage\", \"pre-processing step\", \"supervised learning\"], \"Metric\": [\"time complexity\"], \"OtherScientificTerm\": [\"object poses\", \"changing illumination conditions\", \"partial occlusions\", \"gradient space\", \"cluttered backgrounds\", \"local histograms of oriented gradients (HOGs)\", \"orien-tations\"], \"Task\": [\"class problem\", \"classification\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a new approach for building an efficient and robust classifier for the two class problem, that localizes objects that may appear in the image under different orien-tations. In contrast to other works that address this problem using multiple classifiers, each one specialized for a specific orientation, we propose a simple two-step approach with an estimation stage and a classification stage. The estimator yields an initial set of potential object poses that are then validated by the classifier. This methodology allows reducing the time complexity of the algorithm while classification results remain high. The classifier we use in both stages is based on a boosted combination of Random Ferns over local histograms of oriented gradients (HOGs), which we compute during a pre-processing step. Both the use of supervised learning and working on the gradient space makes our approach robust while being efficient at run-time. We show these properties by thorough testing on standard databases and on a new database made of motorbikes under planar rotations, and with challenging conditions such as cluttered backgrounds, changing illumination conditions and partial occlusions.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"building an efficient and robust classifier\", \"localize objects that may appear in the image under different orientations\"], \"Method\": [\"two-step approach\", \"estimation stage\", \"classification stage\", \"boosted combination of Random Ferns over local histograms of oriented gradients (HOGs)\"], \"Metric\": [\"time complexity\", \"classification results\"], \"Material\": [\"standard databases\", \"new database made of motorbikes under planar rotations\"], \"OtherScientificTerm\": [\"Random Ferns\", \"local histograms of oriented gradients (HOGs)\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"building an efficient and robust classifier\", \"localize objects that may appear in the image under different orientations\"], \"Method\": [\"two-step approach\", \"estimation stage\", \"classification stage\", \"boosted combination of Random Ferns over local histograms of oriented gradients (HOGs)\"], \"Metric\": [\"time complexity\", \"classification results\"], \"Material\": [\"standard databases\", \"new database made of motorbikes under planar rotations\"], \"OtherScientificTerm\": [\"Random Ferns\", \"local histograms of oriented gradients (HOGs)\"], \"Generic\": []}"], "doc_hash": "758d3a44163bf17b192c646d0c54dadea58741cf9031dac84c143c96757c808f", "prompt_hash": "8c1fd0663173bee6860fb3c83bb0d11aa4184b87aea8db4e179d913b40954221", "target_hash": "07659cdc110ed600c1c6f9fdbef1aaa327166c1bfbccd25870a3d93f58226ca3", "bypass": null}
{"doc_id": 4, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe following describes recent work on the Lincoln CSR system. Some new variations in semiphone modeling have been tested. A very simple improved duration model has reduced the error rate by about 10% in both triphone and semiphone systems. A new training strategy has been tested which, by itself, did not provide useful improvements but suggests that improvements can be obtained by a related rapid adaptation technique. Finally, the recognizer has been modified to use bigram back-off language models. The system was then transferred from the RM task to the ATIS CSR task and a limited number of development tests performed. Evaluation test results are presented for both the RM and ATIS CSR tasks.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"triphone and semiphone systems\", \"recognizer\", \"bigram back-off language models\", \"duration model\", \"training strategy\", \"semiphone modeling\", \"rapid adaptation technique\", \"Lincoln CSR system\"], \"Metric\": [\"error rate\"], \"OtherScientificTerm\": [], \"Task\": [\"ATIS CSR task\", \"RM and ATIS CSR tasks\", \"RM task\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:12"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"triphone and semiphone systems\", \"recognizer\", \"bigram back-off language models\", \"duration model\", \"training strategy\", \"semiphone modeling\", \"rapid adaptation technique\", \"Lincoln CSR system\"], \"Metric\": [\"error rate\"], \"OtherScientificTerm\": [], \"Task\": [\"ATIS CSR task\", \"RM and ATIS CSR tasks\", \"RM task\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe following describes recent work on the Lincoln CSR system. Some new variations in semiphone modeling have been tested. A very simple improved duration model has reduced the error rate by about 10% in both triphone and semiphone systems. A new training strategy has been tested which, by itself, did not provide useful improvements but suggests that improvements can be obtained by a related rapid adaptation technique. Finally, the recognizer has been modified to use bigram back-off language models. The system was then transferred from the RM task to the ATIS CSR task and a limited number of development tests performed. Evaluation test results are presented for both the RM and ATIS CSR tasks.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"Lincoln CSR system\", \"RM task\", \"ATIS CSR task\"], \"Method\": [\"semiphone modeling\", \"duration model\", \"training strategy\", \"rapid adaptation technique\", \"bigram back-off language models\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"Lincoln CSR system\", \"RM task\", \"ATIS CSR task\"], \"Method\": [\"semiphone modeling\", \"duration model\", \"training strategy\", \"rapid adaptation technique\", \"bigram back-off language models\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [], \"Generic\": []}"], "doc_hash": "6a0b2d2896e97ff863ddaa0ff9c60ef369133c765993941e40cc261673290c25", "prompt_hash": "ff9c5cbd853ef6df393650c1f20f711832d6edf1a588b458d2025f151c73dee8", "target_hash": "50062a56a0dd10116eba256529a2d003eb3ce0979b2d16eab9b3b04fb419b211", "bypass": null}
{"doc_id": 5, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nA new approach for Interactive Machine Translation where the author interacts during the creation or the modification of the document is proposed. The explanation of an ambiguity or an error for the purposes of correction does not use any concepts of the underlying linguistic theory: it is a reformulation of the erroneous or ambiguous sentence. The interaction is limited to the analysis step of the translation process. This paper presents a new interactive disambiguation scheme based on the paraphrasing of a parser 's multiple output. Some examples of paraphrasing ambiguous sentences are presented.", "output": "{\"Generic\": [\"approach\"], \"Material\": [], \"Method\": [\"translation process\", \"paraphrasing\", \"linguistic theory\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"Interactive Machine Translation\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:13"}, "target": "{\"Generic\": [\"approach\"], \"Material\": [], \"Method\": [\"translation process\", \"paraphrasing\", \"linguistic theory\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"Interactive Machine Translation\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nA new approach for Interactive Machine Translation where the author interacts during the creation or the modification of the document is proposed. The explanation of an ambiguity or an error for the purposes of correction does not use any concepts of the underlying linguistic theory: it is a reformulation of the erroneous or ambiguous sentence. The interaction is limited to the analysis step of the translation process. This paper presents a new interactive disambiguation scheme based on the paraphrasing of a parser 's multiple output. Some examples of paraphrasing ambiguous sentences are presented.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"Interactive Machine Translation\"], \"Method\": [\"interactive disambiguation scheme\", \"paraphrasing of a parser's multiple output\"], \"Material\": [], \"OtherScientificTerm\": [\"ambiguous sentence\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"Interactive Machine Translation\"], \"Method\": [\"interactive disambiguation scheme\", \"paraphrasing of a parser's multiple output\"], \"Material\": [], \"OtherScientificTerm\": [\"ambiguous sentence\"], \"Generic\": []}"], "doc_hash": "214c62be114d330b1b05f3d3b83674a3cff1f3c6fcec809e056b53dc0440103d", "prompt_hash": "9a248e8665a788934c518ddfe77f4850aec9f307205853b8be48ad00c90936f3", "target_hash": "8a1bad76c8565a454922903c945615fd6d98cc3f3b7dfbd15e334a681c88e1b8", "bypass": null}
{"doc_id": 6, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation. This method requires a source-language dependency parser, target language word segmentation and an unsupervised word alignment component. We align a parallel corpus, project the source dependency parse onto the target sentence, extract dependency treelet translation pairs, and train a tree-based ordering model. We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser.", "output": "{\"Generic\": [\"approach\"], \"Material\": [\"parallel corpus\"], \"Method\": [\"parser\", \"SMT models\", \"target language word segmentation\", \"decoder\", \"unsupervised word alignment component\", \"source-language dependency parser\", \"phrasal SMT\", \"tree-based ordering model\"], \"Metric\": [], \"OtherScientificTerm\": [\"source dependency parse\", \"linguistic generality\", \"syntactic information\", \"dependency treelet translation pairs\"], \"Task\": [\"phrasal translation\", \"statistical machine translation\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:14"}, "target": "{\"Generic\": [\"approach\"], \"Material\": [\"parallel corpus\"], \"Method\": [\"parser\", \"SMT models\", \"target language word segmentation\", \"decoder\", \"unsupervised word alignment component\", \"source-language dependency parser\", \"phrasal SMT\", \"tree-based ordering model\"], \"Metric\": [], \"OtherScientificTerm\": [\"source dependency parse\", \"linguistic generality\", \"syntactic information\", \"dependency treelet translation pairs\"], \"Task\": [\"phrasal translation\", \"statistical machine translation\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe describe a novel approach to statistical machine translation that combines syntactic information in the source language with recent advances in phrasal translation. This method requires a source-language dependency parser, target language word segmentation and an unsupervised word alignment component. We align a parallel corpus, project the source dependency parse onto the target sentence, extract dependency treelet translation pairs, and train a tree-based ordering model. We describe an efficient decoder and show that using these tree-based models in combination with conventional SMT models provides a promising approach that incorporates the power of phrasal SMT with the linguistic generality available in a parser.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"statistical machine translation\"], \"Method\": [\"source-language dependency parser\", \"target language word segmentation\", \"unsupervised word alignment component\", \"tree-based ordering model\", \"efficient decoder\"], \"Material\": [\"parallel corpus\"], \"OtherScientificTerm\": [\"tree-based models\", \"phrasal SMT\", \"conventional SMT models\"]}"]], "filtered_resps": ["{\"Task\": [\"statistical machine translation\"], \"Method\": [\"source-language dependency parser\", \"target language word segmentation\", \"unsupervised word alignment component\", \"tree-based ordering model\", \"efficient decoder\"], \"Material\": [\"parallel corpus\"], \"OtherScientificTerm\": [\"tree-based models\", \"phrasal SMT\", \"conventional SMT models\"]}"], "doc_hash": "92729c51c5b32f1cdf01831ff0ad342860da144b002c32c299aed77c0fa1f3a9", "prompt_hash": "0ba23aea61fd4e74293125d4c243f2d41503540a7d0279ba79b6271a85aa65fb", "target_hash": "5e5c100b7d68ad869d7af6029fc7168f786b17a30ec23e794600dc93f032bc03", "bypass": null}
{"doc_id": 7, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nVideo provides not only rich visual cues such as motion and appearance, but also much less explored long-range temporal interactions among objects. We aim to capture such interactions and to construct a powerful intermediate-level video representation for subsequent recognition. Motivated by this goal, we seek to obtain spatio-temporal over-segmentation of a video into regions that respect object boundaries and, at the same time, associate object pix-els over many video frames. The contributions of this paper are twofold. First, we develop an efficient spatio-temporal video segmentation algorithm, which naturally incorporates long-range motion cues from the past and future frames in the form of clusters of point tracks with coherent motion. Second, we devise a new track clustering cost function that includes occlusion reasoning, in the form of depth ordering constraints, as well as motion similarity along the tracks. We evaluate the proposed approach on a challenging set of video sequences of office scenes from feature length movies.", "output": "{\"Generic\": [\"approach\"], \"Material\": [\"video sequences of office scenes\", \"Video\", \"movies\"], \"Method\": [\"spatio-temporal video segmentation algorithm\", \"intermediate-level video representation\", \"track clustering cost function\"], \"Metric\": [], \"OtherScientificTerm\": [\"occlusion reasoning\", \"long-range motion cues\", \"long-range temporal interactions\", \"motion\", \"appearance\", \"spatio-temporal over-segmentation\", \"motion similarity\", \"visual cues\", \"clusters of point tracks\", \"object boundaries\", \"depth ordering constraints\"], \"Task\": [\"recognition\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:15"}, "target": "{\"Generic\": [\"approach\"], \"Material\": [\"video sequences of office scenes\", \"Video\", \"movies\"], \"Method\": [\"spatio-temporal video segmentation algorithm\", \"intermediate-level video representation\", \"track clustering cost function\"], \"Metric\": [], \"OtherScientificTerm\": [\"occlusion reasoning\", \"long-range motion cues\", \"long-range temporal interactions\", \"motion\", \"appearance\", \"spatio-temporal over-segmentation\", \"motion similarity\", \"visual cues\", \"clusters of point tracks\", \"object boundaries\", \"depth ordering constraints\"], \"Task\": [\"recognition\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nVideo provides not only rich visual cues such as motion and appearance, but also much less explored long-range temporal interactions among objects. We aim to capture such interactions and to construct a powerful intermediate-level video representation for subsequent recognition. Motivated by this goal, we seek to obtain spatio-temporal over-segmentation of a video into regions that respect object boundaries and, at the same time, associate object pix-els over many video frames. The contributions of this paper are twofold. First, we develop an efficient spatio-temporal video segmentation algorithm, which naturally incorporates long-range motion cues from the past and future frames in the form of clusters of point tracks with coherent motion. Second, we devise a new track clustering cost function that includes occlusion reasoning, in the form of depth ordering constraints, as well as motion similarity along the tracks. We evaluate the proposed approach on a challenging set of video sequences of office scenes from feature length movies.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"construct a powerful intermediate-level video representation for subsequent recognition\"], \"Method\": [\"efficient spatio-temporal video segmentation algorithm\", \"track clustering cost function\"], \"Material\": [\"video sequences of office scenes from feature length movies\"], \"OtherScientificTerm\": [\"spatio-temporal over-segmentation\", \"long-range temporal interactions\", \"object boundaries\", \"point tracks\", \"coherent motion\", \"occlusion reasoning\", \"depth ordering constraints\", \"motion similarity\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"construct a powerful intermediate-level video representation for subsequent recognition\"], \"Method\": [\"efficient spatio-temporal video segmentation algorithm\", \"track clustering cost function\"], \"Material\": [\"video sequences of office scenes from feature length movies\"], \"OtherScientificTerm\": [\"spatio-temporal over-segmentation\", \"long-range temporal interactions\", \"object boundaries\", \"point tracks\", \"coherent motion\", \"occlusion reasoning\", \"depth ordering constraints\", \"motion similarity\"], \"Generic\": []}"], "doc_hash": "e1e71df4b19605f8fb98d92cd6a8e5bb72237549bbda4c6cd2a823a54f548600", "prompt_hash": "c95a375ba2cee2d05e66c7c3d723eff55cd3cb548951e56848c857978faf14af", "target_hash": "cb11ef493ef7f0c4e321109fe1244eaeed1c6d2594570c692f883829c4a13008", "bypass": null}
{"doc_id": 8, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we introduce KAZE features, a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces. Previous approaches detect and describe features at different scale levels by building or approximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In this way, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining superior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable con-ductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.", "output": "{\"Generic\": [\"state-of-the-art methods\"], \"Material\": [\"benchmark datasets\", \"image data\"], \"Method\": [\"multiscale 2D feature detection and description algorithm\", \"SURF\", \"SIFT\", \"KAZE features\", \"nonlinear diffusion filtering\", \"Additive Operator Splitting (AOS) techniques\", \"variable con-ductance diffusion\"], \"Metric\": [\"localization accuracy and distinctiveness\"], \"OtherScientificTerm\": [\"nonlinear scale spaces\", \"nonlinear scale space\", \"boundaries of objects\", \"Gaussian scale space\", \"Gaussian blurring\", \"object boundaries\"], \"Task\": [\"detection\", \"matching application on deformable surfaces\", \"description\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:16"}, "target": "{\"Generic\": [\"state-of-the-art methods\"], \"Material\": [\"benchmark datasets\", \"image data\"], \"Method\": [\"multiscale 2D feature detection and description algorithm\", \"SURF\", \"SIFT\", \"KAZE features\", \"nonlinear diffusion filtering\", \"Additive Operator Splitting (AOS) techniques\", \"variable con-ductance diffusion\"], \"Metric\": [\"localization accuracy and distinctiveness\"], \"OtherScientificTerm\": [\"nonlinear scale spaces\", \"nonlinear scale space\", \"boundaries of objects\", \"Gaussian scale space\", \"Gaussian blurring\", \"object boundaries\"], \"Task\": [\"detection\", \"matching application on deformable surfaces\", \"description\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we introduce KAZE features, a novel multiscale 2D feature detection and description algorithm in nonlinear scale spaces. Previous approaches detect and describe features at different scale levels by building or approximating the Gaussian scale space of an image. However, Gaussian blurring does not respect the natural boundaries of objects and smoothes to the same degree both details and noise, reducing localization accuracy and distinctiveness. In contrast, we detect and describe 2D features in a nonlinear scale space by means of nonlinear diffusion filtering. In this way, we can make blurring locally adaptive to the image data, reducing noise but retaining object boundaries, obtaining superior localization accuracy and distinctiviness. The nonlinear scale space is built using efficient Additive Operator Splitting (AOS) techniques and variable con-ductance diffusion. We present an extensive evaluation on benchmark datasets and a practical matching application on deformable surfaces. Even though our features are somewhat more expensive to compute than SURF due to the construction of the nonlinear scale space, but comparable to SIFT, our results reveal a step forward in performance both in detection and description against previous state-of-the-art methods.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [\"KAZE features\", \"multiscale 2D feature detection and description algorithm\", \"nonlinear scale space\", \"Additive Operator Splitting (AOS) techniques\", \"variable conductance diffusion\"], \"Material\": [], \"OtherScientificTerm\": [\"nonlinear diffusion filtering\", \"Gaussian scale space\", \"Gaussian blurring\", \"localization accuracy\", \"distinctiveness\", \"deformable surfaces\"], \"Generic\": [\"approach\", \"features\", \"image\", \"scale levels\", \"details\", \"noise\", \"object\", \"image data\", \"blurring\", \"techniques\", \"datasets\", \"matching application\", \"features\", \"computation\", \"results\"]}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [\"KAZE features\", \"multiscale 2D feature detection and description algorithm\", \"nonlinear scale space\", \"Additive Operator Splitting (AOS) techniques\", \"variable conductance diffusion\"], \"Material\": [], \"OtherScientificTerm\": [\"nonlinear diffusion filtering\", \"Gaussian scale space\", \"Gaussian blurring\", \"localization accuracy\", \"distinctiveness\", \"deformable surfaces\"], \"Generic\": [\"approach\", \"features\", \"image\", \"scale levels\", \"details\", \"noise\", \"object\", \"image data\", \"blurring\", \"techniques\", \"datasets\", \"matching application\", \"features\", \"computation\", \"results\"]}"], "doc_hash": "edadefc8a9f82de94ab127a3b0142df4b9b33f90572ad83ee37cdaa4b9bd94d7", "prompt_hash": "80710aff8150b74b2857836c55d124b042e35dd0dd68415709bb26ff1d0ecf2f", "target_hash": "21864487b52595a9bf48ce4de332707d63596432c081e093b76abb663ed8d139", "bypass": null}
{"doc_id": 9, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nSemantic Web documents that encode facts about entities on the Web have been growing rapidly in size and evolving over time. Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest. In this paper, we explore automatic summa-rization techniques that characterize and enable identification of an entity and create summaries that are human friendly. Specifically, we highlight the importance of diversified (faceted) summaries by combining three dimensions: diversity, uniqueness, and popularity. Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts, and picks representative facts from each group to form concise (i.e., short) and comprehensive (i.e., improved coverage through diversity) summaries. We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization.", "output": "{\"Generic\": [\"state-of-the-art techniques\"], \"Material\": [\"lengthy Semantic Web documents\", \"Semantic Web documents\"], \"Method\": [\"automatic summa-rization techniques\", \"human conceptual clustering techniques\", \"diversity-aware entity summarization approach\"], \"Metric\": [\"quality\", \"efficiency\"], \"OtherScientificTerm\": [\"uniqueness\", \"popularity\", \"diversity\", \"diversified (faceted) summaries\"], \"Task\": [\"identification of the corresponding entity\", \"entity summarization\", \"Creating summaries\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:17"}, "target": "{\"Generic\": [\"state-of-the-art techniques\"], \"Material\": [\"lengthy Semantic Web documents\", \"Semantic Web documents\"], \"Method\": [\"automatic summa-rization techniques\", \"human conceptual clustering techniques\", \"diversity-aware entity summarization approach\"], \"Metric\": [\"quality\", \"efficiency\"], \"OtherScientificTerm\": [\"uniqueness\", \"popularity\", \"diversity\", \"diversified (faceted) summaries\"], \"Task\": [\"identification of the corresponding entity\", \"entity summarization\", \"Creating summaries\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nSemantic Web documents that encode facts about entities on the Web have been growing rapidly in size and evolving over time. Creating summaries on lengthy Semantic Web documents for quick identification of the corresponding entity has been of great contemporary interest. In this paper, we explore automatic summa-rization techniques that characterize and enable identification of an entity and create summaries that are human friendly. Specifically, we highlight the importance of diversified (faceted) summaries by combining three dimensions: diversity, uniqueness, and popularity. Our novel diversity-aware entity summarization approach mimics human conceptual clustering techniques to group facts, and picks representative facts from each group to form concise (i.e., short) and comprehensive (i.e., improved coverage through diversity) summaries. We evaluate our approach against the state-of-the-art techniques and show that our work improves both the quality and the efficiency of entity summarization.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"automatic summarization techniques\", \"create summaries\"], \"Method\": [\"diversity-aware entity summarization approach\", \"human conceptual clustering techniques\"], \"Metric\": [\"quality\", \"efficiency\"], \"Material\": [], \"OtherScientificTerm\": [\"Semantic Web documents\", \"detailed facts\", \"concise summaries\", \"comprehensive summaries\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"automatic summarization techniques\", \"create summaries\"], \"Method\": [\"diversity-aware entity summarization approach\", \"human conceptual clustering techniques\"], \"Metric\": [\"quality\", \"efficiency\"], \"Material\": [], \"OtherScientificTerm\": [\"Semantic Web documents\", \"detailed facts\", \"concise summaries\", \"comprehensive summaries\"], \"Generic\": []}"], "doc_hash": "5663923136460f3bc4005021a8e1fc02ce99ea8535c0cd6486c049105a6348d1", "prompt_hash": "06b5f3c00bd9e5f29caca7fc67269f970cc59bea638dfd700df12a69c93f9c8e", "target_hash": "a1c545311acc4336f4e43139e7b9a5cbb22ac0ca081ce40a8e5b64dad9f0cfea", "bypass": null}
{"doc_id": 10, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a framework for the fast computation of lexical affinity models. The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms, an independence model, and a parametric affinity model. In comparison with previous models, which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models, in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus. The framework is flexible, allowing fast adaptation to applications and it is scalable. We apply it in combination with a terabyte corpus to answer natural language tests, achieving encouraging results.", "output": "{\"Generic\": [\"framework\", \"models\", \"algorithm\"], \"Material\": [\"terabyte corpus\"], \"Method\": [\"sequential models\", \"parametric affinity model\", \"independence model\"], \"Metric\": [], \"OtherScientificTerm\": [\"co-occurrence distribution\", \"co-occurrence patterns\", \"lexical affinity\", \"similarity\"], \"Task\": [\"natural language tests\", \"fast computation of lexical affinity models\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:18"}, "target": "{\"Generic\": [\"framework\", \"models\", \"algorithm\"], \"Material\": [\"terabyte corpus\"], \"Method\": [\"sequential models\", \"parametric affinity model\", \"independence model\"], \"Metric\": [], \"OtherScientificTerm\": [\"co-occurrence distribution\", \"co-occurrence patterns\", \"lexical affinity\", \"similarity\"], \"Task\": [\"natural language tests\", \"fast computation of lexical affinity models\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a framework for the fast computation of lexical affinity models. The framework is composed of a novel algorithm to efficiently compute the co-occurrence distribution between pairs of terms, an independence model, and a parametric affinity model. In comparison with previous models, which either use arbitrary windows to compute similarity between words or use lexical affinity to create sequential models, in this paper we focus on models intended to capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus. The framework is flexible, allowing fast adaptation to applications and it is scalable. We apply it in combination with a terabyte corpus to answer natural language tests, achieving encouraging results.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"fast computation of lexical affinity models\", \"capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus\"], \"Method\": [\"novel algorithm\", \"independence model\", \"parametric affinity model\"], \"Material\": [\"terabyte corpus\"], \"OtherScientificTerm\": [\"co-occurrence distribution\", \"similarity between words\", \"natural language tests\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"fast computation of lexical affinity models\", \"capture the co-occurrence patterns of any pair of words or phrases at any distance in the corpus\"], \"Method\": [\"novel algorithm\", \"independence model\", \"parametric affinity model\"], \"Material\": [\"terabyte corpus\"], \"OtherScientificTerm\": [\"co-occurrence distribution\", \"similarity between words\", \"natural language tests\"], \"Generic\": []}"], "doc_hash": "9da6b9f19266f4fc8d1bf2ef6dc996a42217e90538edcfc2272904d6ae46af70", "prompt_hash": "5347204c99e047cb50387ab61110745237824c9e450eb3c7de0d7e5da273a60e", "target_hash": "c477197463c66e0874c72ed4727dfc3b81a236c590134b76fb7045759cfb3287", "bypass": null}
{"doc_id": 11, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper introduces a system for categorizing unknown words. The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words. The focus of this paper is the components that identify names and spelling errors. Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word. The system is evaluated using data from live closed captions-a genre replete with a wide variety of unknown words.", "output": "{\"Generic\": [\"components\", \"system\"], \"Material\": [\"live closed captions\"], \"Method\": [\"multi-component architecture\", \"decision tree architecture\"], \"Metric\": [], \"OtherScientificTerm\": [\"unknown words\", \"unknown word\", \"spelling errors\", \"names\"], \"Task\": [\"categorizing unknown words\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:19"}, "target": "{\"Generic\": [\"components\", \"system\"], \"Material\": [\"live closed captions\"], \"Method\": [\"multi-component architecture\", \"decision tree architecture\"], \"Metric\": [], \"OtherScientificTerm\": [\"unknown words\", \"unknown word\", \"spelling errors\", \"names\"], \"Task\": [\"categorizing unknown words\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper introduces a system for categorizing unknown words. The system is based on a multi-component architecture where each component is responsible for identifying one class of unknown words. The focus of this paper is the components that identify names and spelling errors. Each component uses a decision tree architecture to combine multiple types of evidence about the unknown word. The system is evaluated using data from live closed captions-a genre replete with a wide variety of unknown words.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"categorizing unknown words\"], \"Method\": [\"multi-component architecture\", \"decision tree architecture\"], \"Material\": [\"live closed captions\"], \"OtherScientificTerm\": []}"]], "filtered_resps": ["{\"Task\": [\"categorizing unknown words\"], \"Method\": [\"multi-component architecture\", \"decision tree architecture\"], \"Material\": [\"live closed captions\"], \"OtherScientificTerm\": []}"], "doc_hash": "1b8ca456c723721e39ceae78a597b49a03e29c741727de2f78205df994ba2c84", "prompt_hash": "198eb7528aacada03d83950c1f43029de91af6290ecc5dede93119e24f42f2f0", "target_hash": "4c878d587c1e4fb79f2b183061c5a9bc60e49e97b902a5bcf25d5bd43d92063f", "bypass": null}
{"doc_id": 12, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAn entity-oriented approach to restricted-domain parsing is proposed. In this approach, the definitions of the structure and surface representation of domain entities are grouped together. Like semantic grammar, this allows easy exploitation of limited domain semantics. In addition, it facilitates fragmentary recognition and the use of multiple parsing strategies, and so is particularly useful for robust recognition of extra-grammatical input. Several advantages from the point of view of language definition are also noted. Representative samples from an entity-oriented language definition are presented, along with a control structure for an entity-oriented parser, some parsing strategies that use the control structure, and worked examples of parses. A parser incorporating the control structure and the parsing strategies is currently under implementation.", "output": "{\"Generic\": [\"this\"], \"Material\": [], \"Method\": [\"entity-oriented parser\", \"parser\", \"parsing strategies\", \"entity-oriented approach\", \"multiple parsing strategies\", \"semantic grammar\"], \"Metric\": [], \"OtherScientificTerm\": [\"entity-oriented language definition\", \"limited domain semantics\", \"structure and surface representation of domain entities\", \"control structure\", \"recognition of extra-grammatical input\"], \"Task\": [\"restricted-domain parsing\", \"fragmentary recognition\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:2"}, "target": "{\"Generic\": [\"this\"], \"Material\": [], \"Method\": [\"entity-oriented parser\", \"parser\", \"parsing strategies\", \"entity-oriented approach\", \"multiple parsing strategies\", \"semantic grammar\"], \"Metric\": [], \"OtherScientificTerm\": [\"entity-oriented language definition\", \"limited domain semantics\", \"structure and surface representation of domain entities\", \"control structure\", \"recognition of extra-grammatical input\"], \"Task\": [\"restricted-domain parsing\", \"fragmentary recognition\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAn entity-oriented approach to restricted-domain parsing is proposed. In this approach, the definitions of the structure and surface representation of domain entities are grouped together. Like semantic grammar, this allows easy exploitation of limited domain semantics. In addition, it facilitates fragmentary recognition and the use of multiple parsing strategies, and so is particularly useful for robust recognition of extra-grammatical input. Several advantages from the point of view of language definition are also noted. Representative samples from an entity-oriented language definition are presented, along with a control structure for an entity-oriented parser, some parsing strategies that use the control structure, and worked examples of parses. A parser incorporating the control structure and the parsing strategies is currently under implementation.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"restricted-domain parsing\"], \"Method\": [\"entity-oriented approach\", \"semantic grammar\"], \"Material\": [], \"OtherScientificTerm\": [\"entity-oriented language definition\", \"control structure\", \"parsing strategies\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"restricted-domain parsing\"], \"Method\": [\"entity-oriented approach\", \"semantic grammar\"], \"Material\": [], \"OtherScientificTerm\": [\"entity-oriented language definition\", \"control structure\", \"parsing strategies\"], \"Generic\": []}"], "doc_hash": "42a5ee030e72676bdb29768cdffcaf8747a076ef3d8e2fcb353ef0ff2ebcf4a1", "prompt_hash": "0baafbdf7045696ebc4edb4ae8d1968823979a8bc93fe3f6a8ae0a5e9e88d229", "target_hash": "c4f5b0bfa4f3b2aa13cfb6f930a6dc5239b326ca4ef953a041c50a87e19a144e", "bypass": null}
{"doc_id": 13, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAt MIT Lincoln Laboratory, we have been developing a Korean-to-English machine translation system CCLINC (Common Coalition Language System at Lincoln Laboratory). The CCLINC Korean-to-English translation system consists of two core modules, language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame. The key features of the system include: (i) Robust efficient parsing of Korean (a verb final language with overt case markers, relatively free word order, and frequent omissions of arguments). (ii) High quality translation via word sense disambiguation and accurate word order generation of the target language. (iii) Rapid system development and porting to new domains via knowledge-based automated acquisition of grammars. Having been trained on Korean newspaper articles on missiles and chemical biological warfare, the system produces the translation output sufficient for content understanding of the original document.", "output": "{\"Generic\": [\"core modules\"], \"Material\": [\"verb final language\", \"missiles and chemical biological warfare\", \"Korean newspaper articles\", \"Korean\"], \"Method\": [\"CCLINC (Common Coalition Language System at Lincoln Laboratory)\", \"word sense disambiguation\", \"Korean-to-English machine translation system\", \"language neutral meaning representation\", \"knowledge-based automated acquisition of grammars\"], \"Metric\": [], \"OtherScientificTerm\": [\"overt case markers\", \"semantic frame\"], \"Task\": [\"word order generation\", \"parsing of Korean\", \"translation\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:20"}, "target": "{\"Generic\": [\"core modules\"], \"Material\": [\"verb final language\", \"missiles and chemical biological warfare\", \"Korean newspaper articles\", \"Korean\"], \"Method\": [\"CCLINC (Common Coalition Language System at Lincoln Laboratory)\", \"word sense disambiguation\", \"Korean-to-English machine translation system\", \"language neutral meaning representation\", \"knowledge-based automated acquisition of grammars\"], \"Metric\": [], \"OtherScientificTerm\": [\"overt case markers\", \"semantic frame\"], \"Task\": [\"word order generation\", \"parsing of Korean\", \"translation\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAt MIT Lincoln Laboratory, we have been developing a Korean-to-English machine translation system CCLINC (Common Coalition Language System at Lincoln Laboratory). The CCLINC Korean-to-English translation system consists of two core modules, language understanding and generation modules mediated by a language neutral meaning representation called a semantic frame. The key features of the system include: (i) Robust efficient parsing of Korean (a verb final language with overt case markers, relatively free word order, and frequent omissions of arguments). (ii) High quality translation via word sense disambiguation and accurate word order generation of the target language. (iii) Rapid system development and porting to new domains via knowledge-based automated acquisition of grammars. Having been trained on Korean newspaper articles on missiles and chemical biological warfare, the system produces the translation output sufficient for content understanding of the original document.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"machine translation system\", \"Korean-to-English machine translation system\"], \"Method\": [\"language understanding\", \"generation modules\", \"language neutral meaning representation\", \"semantic frame\", \"knowledge-based automated acquisition of grammars\"], \"Material\": [\"Korean newspaper articles on missiles and chemical biological warfare\"], \"OtherScientificTerm\": [\"verb final language\", \"overt case markers\", \"free word order\", \"arguments\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"machine translation system\", \"Korean-to-English machine translation system\"], \"Method\": [\"language understanding\", \"generation modules\", \"language neutral meaning representation\", \"semantic frame\", \"knowledge-based automated acquisition of grammars\"], \"Material\": [\"Korean newspaper articles on missiles and chemical biological warfare\"], \"OtherScientificTerm\": [\"verb final language\", \"overt case markers\", \"free word order\", \"arguments\"], \"Generic\": []}"], "doc_hash": "8128f23b8505ab11de27f2d2f5102e51cd7e4b406452e9e9777ab85a92ddfdaf", "prompt_hash": "9c9faf56be3bf82b945b141d5725f8535c3879d255d16b3862079b3c94c774d6", "target_hash": "8843ac39e25299c0af1abee9165012066a3c1e03e041eceb1b4e9634a2a0dea0", "bypass": null}
{"doc_id": 14, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe JAVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"language processing modules\", \"JAVELIN system\", \"planning-based architecture\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"open-domain question answering capability\", \"question answering\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:21"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"language processing modules\", \"JAVELIN system\", \"planning-based architecture\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"open-domain question answering capability\", \"question answering\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe JAVELIN system integrates a flexible, planning-based architecture with a variety of language processing modules to provide an open-domain question answering capability on free text. The demonstration will focus on how JAVELIN processes questions and retrieves the most likely answer candidates from the given text corpus. The operation of the system will be explained in depth through browsing the repository of data objects created by the system during each question answering session.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"open-domain question answering\"], \"Method\": [\"flexible, planning-based architecture\", \"language processing modules\"], \"Material\": [\"data objects\", \"question answering session\"], \"OtherScientificTerm\": [\"free text\", \"text corpus\"]}"]], "filtered_resps": ["{\"Task\": [\"open-domain question answering\"], \"Method\": [\"flexible, planning-based architecture\", \"language processing modules\"], \"Material\": [\"data objects\", \"question answering session\"], \"OtherScientificTerm\": [\"free text\", \"text corpus\"]}"], "doc_hash": "904a7a6afb4089b193a82418a733dbce491c6c8780ba91d0df035957730cf43e", "prompt_hash": "c126a6a547f02625188b5cf298c20d3c3c1d3e616db06a5d41bdde24f99586b4", "target_hash": "7ca642f834217be43c556951c150928ba7b01d125f52430e785994b9981a3caa", "bypass": null}
{"doc_id": 15, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present the first application of the head-driven statistical parsing model of Collins (1999) as a simultaneous language model and parser for large-vocabulary speech recognition. The model is adapted to an online left to right chart-parser for word lattices, integrating acoustic, n-gram, and parser probabilities. The parser uses structural and lexical dependencies not considered by n-gram models, conditioning recognition on more linguistically-grounded relationships. Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding.", "output": "{\"Generic\": [], \"Material\": [\"lattice corpora\", \"Wall Street Journal treebank\"], \"Method\": [\"n-gram language model\", \"simultaneous language model\", \"n-gram models\", \"head-driven statistical parsing model\", \"online left to right chart-parser\"], \"Metric\": [\"word error rates\"], \"OtherScientificTerm\": [\"structural and lexical dependencies\", \"structural information\", \"acoustic , n-gram , and parser probabilities\", \"word lattices\"], \"Task\": [\"speech understanding\", \"large-vocabulary speech recognition\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:22"}, "target": "{\"Generic\": [], \"Material\": [\"lattice corpora\", \"Wall Street Journal treebank\"], \"Method\": [\"n-gram language model\", \"simultaneous language model\", \"n-gram models\", \"head-driven statistical parsing model\", \"online left to right chart-parser\"], \"Metric\": [\"word error rates\"], \"OtherScientificTerm\": [\"structural and lexical dependencies\", \"structural information\", \"acoustic , n-gram , and parser probabilities\", \"word lattices\"], \"Task\": [\"speech understanding\", \"large-vocabulary speech recognition\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present the first application of the head-driven statistical parsing model of Collins (1999) as a simultaneous language model and parser for large-vocabulary speech recognition. The model is adapted to an online left to right chart-parser for word lattices, integrating acoustic, n-gram, and parser probabilities. The parser uses structural and lexical dependencies not considered by n-gram models, conditioning recognition on more linguistically-grounded relationships. Experiments on the Wall Street Journal treebank and lattice corpora show word error rates competitive with the standard n-gram language model while extracting additional structural information useful for speech understanding.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"speech recognition\", \"language model\"], \"Method\": [\"head-driven statistical parsing model\", \"left to right chart-parser\", \"acoustic, n-gram, and parser probabilities\"], \"Material\": [\"Wall Street Journal treebank\", \"lattice corpora\"], \"OtherScientificTerm\": [\"treebank\", \"lattice\", \"n-gram model\"]}"]], "filtered_resps": ["{\"Task\": [\"speech recognition\", \"language model\"], \"Method\": [\"head-driven statistical parsing model\", \"left to right chart-parser\", \"acoustic, n-gram, and parser probabilities\"], \"Material\": [\"Wall Street Journal treebank\", \"lattice corpora\"], \"OtherScientificTerm\": [\"treebank\", \"lattice\", \"n-gram model\"]}"], "doc_hash": "ab898a1965add893289761c76e13c92b18e0eb6546839e7d184bd01ac11a2441", "prompt_hash": "63436e02c0813879d42b904b3cc0bd8f8546e1c2a765b15d719da9f6f3e14967", "target_hash": "aab803786153c2b19b70db5dfc0414d4c7d13be2c94cdcc7ccb006b831b7dea7", "bypass": null}
{"doc_id": 16, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nImage composition (or mosaicing) has attracted a growing attention in recent years as one of the main elements in video analysis and representation. In this paper we deal with the problem of global alignment and super-resolution. We also propose to evaluate the quality of the resulting mosaic by measuring the amount of blurring. Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps. Experimental comparison with other techniques shows the effectiveness of our approach.", "output": "{\"Generic\": [\"techniques\"], \"Material\": [], \"Method\": [\"bundle adjustment\", \"graph-based technique\"], \"Metric\": [\"amount of blurring\"], \"OtherScientificTerm\": [\"topological structure\", \"homographies\", \"spatial overlap\"], \"Task\": [\"Image composition (or mosaicing)\", \"video analysis and representation\", \"global alignment\", \"mosaic\", \"super-resolution\", \"Global registration\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:23"}, "target": "{\"Generic\": [\"techniques\"], \"Material\": [], \"Method\": [\"bundle adjustment\", \"graph-based technique\"], \"Metric\": [\"amount of blurring\"], \"OtherScientificTerm\": [\"topological structure\", \"homographies\", \"spatial overlap\"], \"Task\": [\"Image composition (or mosaicing)\", \"video analysis and representation\", \"global alignment\", \"mosaic\", \"super-resolution\", \"Global registration\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nImage composition (or mosaicing) has attracted a growing attention in recent years as one of the main elements in video analysis and representation. In this paper we deal with the problem of global alignment and super-resolution. We also propose to evaluate the quality of the resulting mosaic by measuring the amount of blurring. Global registration is achieved by combining a graph-based technique -- that exploits the topological structure of the sequence induced by the spatial overlap -- with a bundle adjustment which uses only the homographies computed in the previous steps. Experimental comparison with other techniques shows the effectiveness of our approach.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"image composition\", \"global alignment\", \"super-resolution\"], \"Method\": [\"graph-based technique\", \"bundle adjustment\", \"homographies\"], \"Metric\": [\"amount of blurring\"], \"Material\": [], \"OtherScientificTerm\": [\"topological structure\", \"spatial overlap\", \"sequence\", \"techniques\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"image composition\", \"global alignment\", \"super-resolution\"], \"Method\": [\"graph-based technique\", \"bundle adjustment\", \"homographies\"], \"Metric\": [\"amount of blurring\"], \"Material\": [], \"OtherScientificTerm\": [\"topological structure\", \"spatial overlap\", \"sequence\", \"techniques\"], \"Generic\": []}"], "doc_hash": "9d3d268f0f1992d839333f4f123f2539c53d93c141264f8d2d2bf20ccb198e0b", "prompt_hash": "b668c7e8e4376a99152d7e9043ada57090725c26cf38601e40ac1d5bbb2ba32c", "target_hash": "91c7cb5dabb950eb9d1deac0a759aab84f409c77d1a63885966ebe0a2241f061", "bypass": null}
{"doc_id": 17, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe project presented here is a part of a long term research program aiming at a full lexicon grammar for Polish (SyntLex). The main of this project is computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish. We present methodology and resources obtained in three main project phases which are: dictionary-based acquisition of collocation lexicon, feasibility study for corpus-based lexicon enlargement phase, corpus-based lexicon enlargement and collocation description. In this paper we focus on the results of the third phase. The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish. In the paper we describe the SyntLex Dictionary of Collocations and announce some future research intended to be a separate project continuation.", "output": "{\"Generic\": [\"phases\"], \"Material\": [\"verb-noun collocation dictionary\", \"Polish\", \"SyntLex Dictionary of Collocations\"], \"Method\": [\"lexicon grammar for Polish (SyntLex)\", \"corpus-based approach\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"corpus-based lexicon enlargement phase\", \"corpus-based lexicon enlargement and collocation description\", \"computer-assisted acquisition and morpho-syntactic description of verb-noun collocations\", \"dictionary-based acquisition of collocation lexicon\", \"feasibility study\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:24"}, "target": "{\"Generic\": [\"phases\"], \"Material\": [\"verb-noun collocation dictionary\", \"Polish\", \"SyntLex Dictionary of Collocations\"], \"Method\": [\"lexicon grammar for Polish (SyntLex)\", \"corpus-based approach\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"corpus-based lexicon enlargement phase\", \"corpus-based lexicon enlargement and collocation description\", \"computer-assisted acquisition and morpho-syntactic description of verb-noun collocations\", \"dictionary-based acquisition of collocation lexicon\", \"feasibility study\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe project presented here is a part of a long term research program aiming at a full lexicon grammar for Polish (SyntLex). The main of this project is computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish. We present methodology and resources obtained in three main project phases which are: dictionary-based acquisition of collocation lexicon, feasibility study for corpus-based lexicon enlargement phase, corpus-based lexicon enlargement and collocation description. In this paper we focus on the results of the third phase. The presented here corpus-based approach permitted us to triple the size the verb-noun collocation dictionary for Polish. In the paper we describe the SyntLex Dictionary of Collocations and announce some future research intended to be a separate project continuation.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish\", \"full lexicon grammar for Polish (SyntLex)\"], \"Method\": [\"dictionary-based acquisition of collocation lexicon\", \"feasibility study\", \"corpus-based lexicon enlargement and collocation description\"], \"Material\": [\"SyntLex Dictionary of Collocations\"], \"OtherScientificTerm\": [\"verb-noun collocations\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"computer-assisted acquisition and morpho-syntactic description of verb-noun collocations in Polish\", \"full lexicon grammar for Polish (SyntLex)\"], \"Method\": [\"dictionary-based acquisition of collocation lexicon\", \"feasibility study\", \"corpus-based lexicon enlargement and collocation description\"], \"Material\": [\"SyntLex Dictionary of Collocations\"], \"OtherScientificTerm\": [\"verb-noun collocations\"], \"Generic\": []}"], "doc_hash": "29abecf715b576980c2a553423a45fbbaee1a99353137f400ef0a2fd2a1a7dc2", "prompt_hash": "e3d8bb71f2c04f13be506530bb1863deb9763e475a907b17881a760d046d784b", "target_hash": "5a8a57fb0e8021d2f0b3d4f7d7e699eea483c96f431c1875cd09d19b3ee584f4", "bypass": null}
{"doc_id": 18, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAlong with the increasing requirements, the hash-tag recommendation task for microblogs has been receiving considerable attention in recent years. Various researchers have studied the problem from different aspects. However, most of these methods usually need handcrafted features. Motivated by the successful use of convolutional neural networks (CNNs) for many natural language processing tasks, in this paper, we adopt CNNs to perform the hashtag recommendation problem. To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works, we propose a novel architecture with an attention mechanism. The results of experiments on the data collected from a real world microblogging service demonstrated that the proposed model outperforms state-of-the-art methods. By incorporating trigger words into the consideration, the relative improvement of the proposed method over the state-of-the-art method is around 9.4% in the F1-score.", "output": "{\"Generic\": [\"architecture\", \"data\", \"state-of-the-art methods\"], \"Material\": [\"microblogs\"], \"Method\": [\"convolutional neural networks (CNNs)\"], \"Metric\": [\"F1-score\"], \"OtherScientificTerm\": [\"attention mechanism\", \"trigger words\", \"handcrafted features\"], \"Task\": [\"hash-tag recommendation task\", \"natural language processing tasks\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:25"}, "target": "{\"Generic\": [\"architecture\", \"data\", \"state-of-the-art methods\"], \"Material\": [\"microblogs\"], \"Method\": [\"convolutional neural networks (CNNs)\"], \"Metric\": [\"F1-score\"], \"OtherScientificTerm\": [\"attention mechanism\", \"trigger words\", \"handcrafted features\"], \"Task\": [\"hash-tag recommendation task\", \"natural language processing tasks\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAlong with the increasing requirements, the hash-tag recommendation task for microblogs has been receiving considerable attention in recent years. Various researchers have studied the problem from different aspects. However, most of these methods usually need handcrafted features. Motivated by the successful use of convolutional neural networks (CNNs) for many natural language processing tasks, in this paper, we adopt CNNs to perform the hashtag recommendation problem. To incorporate the trigger words whose effectiveness have been experimentally evaluated in several previous works, we propose a novel architecture with an attention mechanism. The results of experiments on the data collected from a real world microblogging service demonstrated that the proposed model outperforms state-of-the-art methods. By incorporating trigger words into the consideration, the relative improvement of the proposed method over the state-of-the-art method is around 9.4% in the F1-score.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"hash-tag recommendation task for microblogs\"], \"Method\": [\"convolutional neural networks (CNNs)\", \"attention mechanism\"], \"Metric\": [\"F1-score\"], \"Material\": [], \"OtherScientificTerm\": [\"handcrafted features\", \"trigger words\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"hash-tag recommendation task for microblogs\"], \"Method\": [\"convolutional neural networks (CNNs)\", \"attention mechanism\"], \"Metric\": [\"F1-score\"], \"Material\": [], \"OtherScientificTerm\": [\"handcrafted features\", \"trigger words\"], \"Generic\": []}"], "doc_hash": "bba7da5e96fb81fbeb8c99dcf4cd66b493f4789b2eeb7cbb1017a5c18f5ffcfb", "prompt_hash": "652247869b0f8829cef952bd9460389bf22517acee82fc275ce622ab8bda22ff", "target_hash": "b581ca859b3f48cb2eee284dcdab8dc4c87c1a9eb224406b321229c10658f3dd", "bypass": null}
{"doc_id": 19, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we improve an unsupervised learning method using the Expectation-Maximization (EM) algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation (WSD) problems. The improved method stops the EM algorithm at the optimum iteration number. To estimate that number, we propose two methods. In experiments, we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2. The score of our method is a match for the best public score of this task. Furthermore, our methods were confirmed to be effective also for verb WSD problems.", "output": "{\"Generic\": [], \"Material\": [\"SENSEVAL2\"], \"Method\": [\"EM algorithm\", \"Expectation-Maximization (EM) algorithm\", \"unsupervised learning method\"], \"Metric\": [], \"OtherScientificTerm\": [\"optimum iteration number\"], \"Task\": [\"Japanese Dictionary Task\", \"word sense disambiguation (WSD) problems\", \"noun WSD problems\", \"text classification problems\", \"verb WSD problems\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:26"}, "target": "{\"Generic\": [], \"Material\": [\"SENSEVAL2\"], \"Method\": [\"EM algorithm\", \"Expectation-Maximization (EM) algorithm\", \"unsupervised learning method\"], \"Metric\": [], \"OtherScientificTerm\": [\"optimum iteration number\"], \"Task\": [\"Japanese Dictionary Task\", \"word sense disambiguation (WSD) problems\", \"noun WSD problems\", \"text classification problems\", \"verb WSD problems\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we improve an unsupervised learning method using the Expectation-Maximization (EM) algorithm proposed by Nigam et al. for text classification problems in order to apply it to word sense disambiguation (WSD) problems. The improved method stops the EM algorithm at the optimum iteration number. To estimate that number, we propose two methods. In experiments, we solved 50 noun WSD problems in the Japanese Dictionary Task in SENSEVAL2. The score of our method is a match for the best public score of this task. Furthermore, our methods were confirmed to be effective also for verb WSD problems.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"text classification problems\", \"word sense disambiguation (WSD) problems\", \"Japanese Dictionary Task in SENSEVAL2\"], \"Method\": [\"Expectation-Maximization (EM) algorithm\", \"unsupervised learning method\", \"two methods\"], \"Material\": [], \"OtherScientificTerm\": [\"EM algorithm\", \"SENSEVAL2\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"text classification problems\", \"word sense disambiguation (WSD) problems\", \"Japanese Dictionary Task in SENSEVAL2\"], \"Method\": [\"Expectation-Maximization (EM) algorithm\", \"unsupervised learning method\", \"two methods\"], \"Material\": [], \"OtherScientificTerm\": [\"EM algorithm\", \"SENSEVAL2\"], \"Generic\": []}"], "doc_hash": "447c6e1c579decd943adc9672475a42e92953463832d79649cae544349f96265", "prompt_hash": "0ff08c003288946dbbab9b838290532013ceb16be38d380a06b883c567ce5ded", "target_hash": "7733f4f58527ebbc6758a05592a46e1c725243a95734b2e2851742d737e249f1", "bypass": null}
{"doc_id": 20, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nDividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval. (Ramshaw and Marcus, 1995) have introduced a 'convenient' data representation for chunking by converting it to a tagging task. In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks. We will show that the data representation choice has a minor influence on chunking performance. However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set.", "output": "{\"Generic\": [], \"Material\": [\"data set\"], \"Method\": [\"data representations\", \"memory-based learning chunker\", \"data representation\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"information retrieval\", \"parsing\", \"tagging task\", \"recognizing noun phrase chunks\", \"information extraction\", \"Dividing sentences in chunks of words\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:27"}, "target": "{\"Generic\": [], \"Material\": [\"data set\"], \"Method\": [\"data representations\", \"memory-based learning chunker\", \"data representation\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"information retrieval\", \"parsing\", \"tagging task\", \"recognizing noun phrase chunks\", \"information extraction\", \"Dividing sentences in chunks of words\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nDividing sentences in chunks of words is a useful preprocessing step for parsing, information extraction and information retrieval. (Ramshaw and Marcus, 1995) have introduced a 'convenient' data representation for chunking by converting it to a tagging task. In this paper we will examine seven different data representations for the problem of recognizing noun phrase chunks. We will show that the data representation choice has a minor influence on chunking performance. However, equipped with the most suitable data representation, our memory-based learning chunker was able to improve the best published chunking results for a standard data set.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"chunking\", \"parsing\", \"information extraction\", \"information retrieval\"], \"Method\": [\"tagging task\", \"memory-based learning chunker\"], \"Material\": [\"standard data set\"], \"OtherScientificTerm\": [\"data representation\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"chunking\", \"parsing\", \"information extraction\", \"information retrieval\"], \"Method\": [\"tagging task\", \"memory-based learning chunker\"], \"Material\": [\"standard data set\"], \"OtherScientificTerm\": [\"data representation\"], \"Generic\": []}"], "doc_hash": "9a3d919bcbefd95b1f1b2f9006b986f27d22fd0eca1500b4e570d9d89f98d1b9", "prompt_hash": "7ed8a7d368fa6880bf15ce146f6c9cd52c01a1ed44e28be82c605baf20c0952c", "target_hash": "9ffba7c1fea379e597e0137c1264aa53b579dd1557e1e9ef8a5f719d3fa23dca", "bypass": null}
{"doc_id": 21, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we describe and evaluate a Question Answering system that goes beyond answering factoid questions. We focus on FAQ-like questions and answers, and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms, trained on a corpus of 1 million question/answer pairs collected from the Web.", "output": "{\"Generic\": [], \"Material\": [\"Web\", \"FAQ-like questions and answers\"], \"Method\": [\"language model\", \"Question Answering system\", \"transformation model\", \"noisy-channel architecture\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:28"}, "target": "{\"Generic\": [], \"Material\": [\"Web\", \"FAQ-like questions and answers\"], \"Method\": [\"language model\", \"Question Answering system\", \"transformation model\", \"noisy-channel architecture\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we describe and evaluate a Question Answering system that goes beyond answering factoid questions. We focus on FAQ-like questions and answers, and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms, trained on a corpus of 1 million question/answer pairs collected from the Web.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"Question Answering system\", \"FAQ-like questions and answers\"], \"Method\": [\"noisy-channel architecture\", \"language model\", \"transformation model\"], \"Material\": [\"1 million question/answer pairs collected from the Web\"], \"OtherScientificTerm\": [\"corpus\"]}"]], "filtered_resps": ["{\"Task\": [\"Question Answering system\", \"FAQ-like questions and answers\"], \"Method\": [\"noisy-channel architecture\", \"language model\", \"transformation model\"], \"Material\": [\"1 million question/answer pairs collected from the Web\"], \"OtherScientificTerm\": [\"corpus\"]}"], "doc_hash": "a48a35bcaa406d0749aaf475357b8adc7e3bb951cc128d2c9147d9c9cdc0a713", "prompt_hash": "d04bc40168fa079fcd57b5c702efaf9e9bdd4c25ae589e4e25fe17cfe13b3c43", "target_hash": "29e7c9b8db0f183b09b7d9784288c3ebb2a86fd841b712b7432537c2b849b8e0", "bypass": null}
{"doc_id": 22, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations. We evaluated three intel-ligibility measures, the Dau measure, the glimpse proportion and the Speech Intelligibility Index (SII) and a quality measure, the Perceptual Evaluation of Speech Quality (PESQ). For the generation of synthesized speech we used a state of the art HMM-based speech synthesis system. The noisy conditions comprised four additive noises. The measures were compared with subjective intelligibility scores obtained in listening tests. The results show the Dau and the glimpse measures to be the best predictors of intelligibility, with correlations of around 0.83 to subjective scores. All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech; in particular the SII measure. In additional experiments, we processed the synthesized speech by an ideal binary mask before adding noise. The Glimpse measure gave the most accurate intelligibility predictions in this situation.", "output": "{\"Generic\": [], \"Material\": [\"natural speech\", \"synthesized speech\", \"synthetic speech\"], \"Method\": [\"predictors of intelligibility\", \"HMM-based speech synthesis system\", \"ideal binary mask\"], \"Metric\": [\"Perceptual Evaluation of Speech Quality (PESQ)\", \"SII measure\", \"quality measure\", \"subjective intelligibility scores\", \"Dau measure\", \"measures of speech\", \"glimpse proportion\", \"intel-ligibility measures\", \"correlations\", \"Speech Intelligibility Index (SII)\"], \"OtherScientificTerm\": [\"noisy conditions\", \"subjective scores\", \"additive noises\", \"diverse noisy situations\"], \"Task\": [\"intelligibility prediction\", \"generation of synthesized speech\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:29"}, "target": "{\"Generic\": [], \"Material\": [\"natural speech\", \"synthesized speech\", \"synthetic speech\"], \"Method\": [\"predictors of intelligibility\", \"HMM-based speech synthesis system\", \"ideal binary mask\"], \"Metric\": [\"Perceptual Evaluation of Speech Quality (PESQ)\", \"SII measure\", \"quality measure\", \"subjective intelligibility scores\", \"Dau measure\", \"measures of speech\", \"glimpse proportion\", \"intel-ligibility measures\", \"correlations\", \"Speech Intelligibility Index (SII)\"], \"OtherScientificTerm\": [\"noisy conditions\", \"subjective scores\", \"additive noises\", \"diverse noisy situations\"], \"Task\": [\"intelligibility prediction\", \"generation of synthesized speech\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we evaluate four objective measures of speech with regards to intelligibility prediction of synthesized speech in diverse noisy situations. We evaluated three intel-ligibility measures, the Dau measure, the glimpse proportion and the Speech Intelligibility Index (SII) and a quality measure, the Perceptual Evaluation of Speech Quality (PESQ). For the generation of synthesized speech we used a state of the art HMM-based speech synthesis system. The noisy conditions comprised four additive noises. The measures were compared with subjective intelligibility scores obtained in listening tests. The results show the Dau and the glimpse measures to be the best predictors of intelligibility, with correlations of around 0.83 to subjective scores. All measures gave less accurate predictions of intelligibility for synthetic speech than have previously been found for natural speech; in particular the SII measure. In additional experiments, we processed the synthesized speech by an ideal binary mask before adding noise. The Glimpse measure gave the most accurate intelligibility predictions in this situation.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"intelligibility prediction of synthesized speech\"], \"Method\": [\"HMM-based speech synthesis system\", \"Dau measure\", \"glimpse proportion\", \"Speech Intelligibility Index (SII)\", \"Perceptual Evaluation of Speech Quality (PESQ)\"], \"Material\": [\"speech data\", \"noisy conditions\", \"listening tests\"], \"OtherScientificTerm\": [\"subjective intelligibility scores\", \"ideal binary mask\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"intelligibility prediction of synthesized speech\"], \"Method\": [\"HMM-based speech synthesis system\", \"Dau measure\", \"glimpse proportion\", \"Speech Intelligibility Index (SII)\", \"Perceptual Evaluation of Speech Quality (PESQ)\"], \"Material\": [\"speech data\", \"noisy conditions\", \"listening tests\"], \"OtherScientificTerm\": [\"subjective intelligibility scores\", \"ideal binary mask\"], \"Generic\": []}"], "doc_hash": "059aa91432abceaa3d62c269e5f855b31c99a4d5080fc0fc71648b5e91a0c2fd", "prompt_hash": "b455252c8a285687ddcf317ece75fb6f05c9708de99e2272c641a300d2b82a03", "target_hash": "d4a06cc31deec5141a6282f0e8b70ff8eb666e96985a25d947e6516d0850555b", "bypass": null}
{"doc_id": 23, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper summarizes the formalism of Category Cooccurrence Restrictions (CCRs) and describes two parsing algorithms that interpret it. CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms. The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements. The paper shows how conventional algorithms for the analysis of context free languages can be adapted to the CCR formalism. Special attention is given to the part of the parser that checks the fulfillment of logical well-formedness conditions on trees.", "output": "{\"Generic\": [\"it\"], \"Material\": [\"context free languages\"], \"Method\": [\"parsing algorithms\", \"syntax formalisms\"], \"Metric\": [], \"OtherScientificTerm\": [\"local trees\", \"syntactic descriptions\", \"Category Cooccurrence Restrictions (CCRs)\", \"restrictive statements\", \"logical well-formedness conditions\", \"trees\", \"statement of generalizations\", \"Boolean conditions\"], \"Task\": [\"formalism of Category Cooccurrence Restrictions (CCRs)\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:3"}, "target": "{\"Generic\": [\"it\"], \"Material\": [\"context free languages\"], \"Method\": [\"parsing algorithms\", \"syntax formalisms\"], \"Metric\": [], \"OtherScientificTerm\": [\"local trees\", \"syntactic descriptions\", \"Category Cooccurrence Restrictions (CCRs)\", \"restrictive statements\", \"logical well-formedness conditions\", \"trees\", \"statement of generalizations\", \"Boolean conditions\"], \"Task\": [\"formalism of Category Cooccurrence Restrictions (CCRs)\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper summarizes the formalism of Category Cooccurrence Restrictions (CCRs) and describes two parsing algorithms that interpret it. CCRs are Boolean conditions on the cooccurrence of categories in local trees which allow the statement of generalizations which can not be captured in other current syntax formalisms. The use of CCRs leads to syntactic descriptions formulated entirely with restrictive statements. The paper shows how conventional algorithms for the analysis of context free languages can be adapted to the CCR formalism. Special attention is given to the part of the parser that checks the fulfillment of logical well-formedness conditions on trees.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"Category Cooccurrence Restrictions\", \"CCRs\", \"Boolean conditions\", \"local trees\", \"context free languages\", \"logical well-formedness conditions\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"Category Cooccurrence Restrictions\", \"CCRs\", \"Boolean conditions\", \"local trees\", \"context free languages\", \"logical well-formedness conditions\"], \"Generic\": []}"], "doc_hash": "99a75b2610570bfc39f6198ce34fa4c60c6284582d53bec823fab5b84cb0928c", "prompt_hash": "de00e2671995a4d607f696699f74be77210880ff31015c23e0405705c9331f33", "target_hash": "3e7d3d813766a28e1d6c3153f437948dc07d6cefb7172afeee10f6ca535bc0e7", "bypass": null}
{"doc_id": 24, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nA 'graphics for vision' approach is proposed to address the problem of reconstruction from a large and imperfect data set: reconstruction on demand by tensor voting, or ROD-TV. ROD-TV simultaneously delivers good efficiency and robust-ness, by adapting to a continuum of primitive connectivity, view dependence, and levels of detail (LOD). Locally inferred surface elements are robust to noise and better capture local shapes. By inferring per-vertex normals at sub-voxel precision on the fly, we can achieve interpolative shading. Since these missing details can be recovered at the current level of detail, our result is not upper bounded by the scanning resolution. By relaxing the mesh connectivity requirement, we extend ROD-TV and propose a simple but effective multiscale feature extraction algorithm. ROD-TV consists of a hierarchical data structure that encodes different levels of detail. The local reconstruction algorithm is tensor voting. It is applied on demand to the visible subset of data at a desired level of detail, by traversing the data hierarchy and collecting tensorial support in a neighborhood. We compare our approach and present encouraging results.", "output": "{\"Generic\": [], \"Material\": [\"large and imperfect data set\"], \"Method\": [\"hierarchical data structure\", \"\\u0027graphics for vision\\u0027 approach\", \"collecting tensorial support\", \"tensor voting\", \"multiscale feature extraction algorithm\", \"ROD-TV\", \"traversing the data hierarchy\", \"local reconstruction algorithm\"], \"Metric\": [\"sub-voxel precision\", \"robust-ness\", \"efficiency\"], \"OtherScientificTerm\": [\"levels of detail (LOD)\", \"local shapes\", \"mesh connectivity requirement\", \"view dependence\", \"primitive connectivity\", \"scanning resolution\", \"per-vertex normals\", \"Locally inferred surface elements\", \"noise\"], \"Task\": [\"reconstruction\", \"interpolative shading\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:30"}, "target": "{\"Generic\": [], \"Material\": [\"large and imperfect data set\"], \"Method\": [\"hierarchical data structure\", \"\\u0027graphics for vision\\u0027 approach\", \"collecting tensorial support\", \"tensor voting\", \"multiscale feature extraction algorithm\", \"ROD-TV\", \"traversing the data hierarchy\", \"local reconstruction algorithm\"], \"Metric\": [\"sub-voxel precision\", \"robust-ness\", \"efficiency\"], \"OtherScientificTerm\": [\"levels of detail (LOD)\", \"local shapes\", \"mesh connectivity requirement\", \"view dependence\", \"primitive connectivity\", \"scanning resolution\", \"per-vertex normals\", \"Locally inferred surface elements\", \"noise\"], \"Task\": [\"reconstruction\", \"interpolative shading\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nA 'graphics for vision' approach is proposed to address the problem of reconstruction from a large and imperfect data set: reconstruction on demand by tensor voting, or ROD-TV. ROD-TV simultaneously delivers good efficiency and robust-ness, by adapting to a continuum of primitive connectivity, view dependence, and levels of detail (LOD). Locally inferred surface elements are robust to noise and better capture local shapes. By inferring per-vertex normals at sub-voxel precision on the fly, we can achieve interpolative shading. Since these missing details can be recovered at the current level of detail, our result is not upper bounded by the scanning resolution. By relaxing the mesh connectivity requirement, we extend ROD-TV and propose a simple but effective multiscale feature extraction algorithm. ROD-TV consists of a hierarchical data structure that encodes different levels of detail. The local reconstruction algorithm is tensor voting. It is applied on demand to the visible subset of data at a desired level of detail, by traversing the data hierarchy and collecting tensorial support in a neighborhood. We compare our approach and present encouraging results.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"reconstruction from a large and imperfect data set\", \"reconstruction on demand by tensor voting\"], \"Method\": [\"graphics for vision approach\", \"tensor voting\", \"ROD-TV\", \"multiscale feature extraction algorithm\", \"hierarchical data structure\", \"local reconstruction algorithm\"], \"Material\": [], \"OtherScientificTerm\": [\"tensorial support\", \"primitive connectivity\", \"view dependence\", \"levels of detail\", \"sub-voxel precision\"], \"Generic\": [\"data\", \"vertex normals\", \"details\", \"mesh connectivity\"]}"]], "filtered_resps": ["{\"Task\": [\"reconstruction from a large and imperfect data set\", \"reconstruction on demand by tensor voting\"], \"Method\": [\"graphics for vision approach\", \"tensor voting\", \"ROD-TV\", \"multiscale feature extraction algorithm\", \"hierarchical data structure\", \"local reconstruction algorithm\"], \"Material\": [], \"OtherScientificTerm\": [\"tensorial support\", \"primitive connectivity\", \"view dependence\", \"levels of detail\", \"sub-voxel precision\"], \"Generic\": [\"data\", \"vertex normals\", \"details\", \"mesh connectivity\"]}"], "doc_hash": "30c294543f481f9289c1f4bf520d741eaf16533dff02cae2d11b898adc0e7f03", "prompt_hash": "daf7cfe45e8dcf550f429b03b677c1571267b31aabc8b6745ec85a42cbe54e5b", "target_hash": "3f1be7fc552700b2d3e406666af6b955873816f61974cfed7f9a9dd028ba7d8d", "bypass": null}
{"doc_id": 25, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nBoth rhetorical structure and punctuation have been helpful in discourse processing. Based on a corpus annotation project, this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts: Colon, Dash, Ellipsis, Exclamation Mark, Question Mark, and Semicolon. The rhetorical patterns of these marks are compared against patterns around cue phrases in general. Results show that these Chinese punctuation marks, though fewer in number than cue phrases, are easy to identify, have strong correlation with certain relations, and can be used as distinctive indicators of nuclearity in Chinese texts.", "output": "{\"Generic\": [], \"Material\": [\"news commentary texts\", \"Chinese texts\"], \"Method\": [], \"Metric\": [], \"OtherScientificTerm\": [\"cue phrases\", \"rhetorical patterns\", \"punctuation\", \"Exclamation Mark\", \"Colon\", \"Chinese punctuation marks\", \"Ellipsis\", \"Question Mark\", \"Semicolon\", \"patterns around cue phrases\", \"rhetorical structure\", \"Dash\", \"indicators of nuclearity\"], \"Task\": [\"discourse processing\", \"discursive usage of 6 Chinese punctuation marks\", \"corpus annotation project\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:31"}, "target": "{\"Generic\": [], \"Material\": [\"news commentary texts\", \"Chinese texts\"], \"Method\": [], \"Metric\": [], \"OtherScientificTerm\": [\"cue phrases\", \"rhetorical patterns\", \"punctuation\", \"Exclamation Mark\", \"Colon\", \"Chinese punctuation marks\", \"Ellipsis\", \"Question Mark\", \"Semicolon\", \"patterns around cue phrases\", \"rhetorical structure\", \"Dash\", \"indicators of nuclearity\"], \"Task\": [\"discourse processing\", \"discursive usage of 6 Chinese punctuation marks\", \"corpus annotation project\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nBoth rhetorical structure and punctuation have been helpful in discourse processing. Based on a corpus annotation project, this paper reports the discursive usage of 6 Chinese punctuation marks in news commentary texts: Colon, Dash, Ellipsis, Exclamation Mark, Question Mark, and Semicolon. The rhetorical patterns of these marks are compared against patterns around cue phrases in general. Results show that these Chinese punctuation marks, though fewer in number than cue phrases, are easy to identify, have strong correlation with certain relations, and can be used as distinctive indicators of nuclearity in Chinese texts.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"discourse processing\"], \"Method\": [], \"Material\": [\"news commentary texts\", \"corpus annotation project\", \"Chinese punctuation marks\", \"cue phrases\"], \"OtherScientificTerm\": [\"rhetorical patterns\", \"relations\", \"nuclearity\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"discourse processing\"], \"Method\": [], \"Material\": [\"news commentary texts\", \"corpus annotation project\", \"Chinese punctuation marks\", \"cue phrases\"], \"OtherScientificTerm\": [\"rhetorical patterns\", \"relations\", \"nuclearity\"], \"Generic\": []}"], "doc_hash": "33b198fd14a1269e237abf4f5993ec5a87d61db9d657572460e7940bac564f23", "prompt_hash": "e102d48232a24fa61edbe07cfcbaeee45c703c1bed3f75d8f8997fc4a7c40e64", "target_hash": "f8f69474aaf6717fd580ce6a8da31f4ca8079a47edd6a8af071e1a212742b56f", "bypass": null}
{"doc_id": 26, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe features based on Markov random field (MRF) models are usually sensitive to the rotation of image textures. This paper develops an anisotropic circular Gaussian MRF (ACGMRF) model for modelling rotated image textures and retrieving rotation-invariant texture features. To overcome the singularity problem of the least squares estimate (LSE) method, an approximate least squares estimate (ALSE) method is proposed to estimate the parameters of the ACGMRF model. The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional (1-D) discrete Fourier transform (DFT). Significantly improved accuracy can be achieved by applying the rotation-invariant features to classify SAR (synthetic aperture radar) sea ice and Brodatz imagery.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"one-dimensional (1-D) discrete Fourier transform (DFT)\", \"least squares estimate (LSE) method\", \"anisotropic circular Gaussian MRF (ACGMRF) model\", \"Markov random field (MRF) models\", \"approximate least squares estimate (ALSE) method\"], \"Metric\": [\"accuracy\"], \"OtherScientificTerm\": [\"parameters of the ACGMRF model\", \"SAR (synthetic aperture radar\", \"features\", \"singularity problem\", \"rotation-invariant features\", \"rotation of image textures\"], \"Task\": [\"modelling rotated image textures\", \"retrieving rotation-invariant texture features\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:32"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"one-dimensional (1-D) discrete Fourier transform (DFT)\", \"least squares estimate (LSE) method\", \"anisotropic circular Gaussian MRF (ACGMRF) model\", \"Markov random field (MRF) models\", \"approximate least squares estimate (ALSE) method\"], \"Metric\": [\"accuracy\"], \"OtherScientificTerm\": [\"parameters of the ACGMRF model\", \"SAR (synthetic aperture radar\", \"features\", \"singularity problem\", \"rotation-invariant features\", \"rotation of image textures\"], \"Task\": [\"modelling rotated image textures\", \"retrieving rotation-invariant texture features\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThe features based on Markov random field (MRF) models are usually sensitive to the rotation of image textures. This paper develops an anisotropic circular Gaussian MRF (ACGMRF) model for modelling rotated image textures and retrieving rotation-invariant texture features. To overcome the singularity problem of the least squares estimate (LSE) method, an approximate least squares estimate (ALSE) method is proposed to estimate the parameters of the ACGMRF model. The rotation-invariant features can be obtained from the parameters of the ACGMRF model by the one-dimensional (1-D) discrete Fourier transform (DFT). Significantly improved accuracy can be achieved by applying the rotation-invariant features to classify SAR (synthetic aperture radar) sea ice and Brodatz imagery.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"classifying SAR sea ice and Brodatz imagery\"], \"Method\": [\"Markov random field (MRF) models\", \"anisotropic circular Gaussian MRF (ACGMRF) model\", \"approximate least squares estimate (ALSE) method\", \"one-dimensional (1-D) discrete Fourier transform (DFT)\"], \"Material\": [\"SAR (synthetic aperture radar) sea ice\", \"Brodatz imagery\"], \"OtherScientificTerm\": [\"rotation-invariant texture features\", \"singularity problem\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"classifying SAR sea ice and Brodatz imagery\"], \"Method\": [\"Markov random field (MRF) models\", \"anisotropic circular Gaussian MRF (ACGMRF) model\", \"approximate least squares estimate (ALSE) method\", \"one-dimensional (1-D) discrete Fourier transform (DFT)\"], \"Material\": [\"SAR (synthetic aperture radar) sea ice\", \"Brodatz imagery\"], \"OtherScientificTerm\": [\"rotation-invariant texture features\", \"singularity problem\"], \"Generic\": []}"], "doc_hash": "7bed23eb0f62db8aa891c5615f901856449ae789b1cbc32190243e6d74225ca4", "prompt_hash": "215852ef518c1088380fac56ec1e665da46af0c2c42f054802acd9ee49a2b56a", "target_hash": "1bccb100a44be52d1c56e8abbc37508129458d78cd907f7cdf249a2ae64e05dd", "bypass": null}
{"doc_id": 27, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nDespite much recent progress on accurate semantic role labeling, previous work has largely used independent classifiers, possibly combined with separate label sequence models via Viterbi decoding. This stands in stark contrast to the linguistic observation that a core argument frame is a joint structure, with strong dependencies between arguments. We show how to build a joint model of argument frames, incorporating novel features that model these interactions into discriminative log-linear models. This system achieves an error reduction of 22% on all arguments and 32% on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank.", "output": "{\"Generic\": [], \"Material\": [\"PropBank\"], \"Method\": [\"discriminative log-linear models\", \"label sequence models\", \"Viterbi decoding\", \"joint model of argument frames\", \"independent classifiers\"], \"Metric\": [\"error reduction\"], \"OtherScientificTerm\": [\"features\", \"gold-standard parse trees\", \"core argument frame\"], \"Task\": [\"semantic role labeling\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:33"}, "target": "{\"Generic\": [], \"Material\": [\"PropBank\"], \"Method\": [\"discriminative log-linear models\", \"label sequence models\", \"Viterbi decoding\", \"joint model of argument frames\", \"independent classifiers\"], \"Metric\": [\"error reduction\"], \"OtherScientificTerm\": [\"features\", \"gold-standard parse trees\", \"core argument frame\"], \"Task\": [\"semantic role labeling\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nDespite much recent progress on accurate semantic role labeling, previous work has largely used independent classifiers, possibly combined with separate label sequence models via Viterbi decoding. This stands in stark contrast to the linguistic observation that a core argument frame is a joint structure, with strong dependencies between arguments. We show how to build a joint model of argument frames, incorporating novel features that model these interactions into discriminative log-linear models. This system achieves an error reduction of 22% on all arguments and 32% on core arguments over a state-of-the art independent classifier for gold-standard parse trees on PropBank.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"semantic role labeling\", \"core argument frame\"], \"Method\": [\"independent classifiers\", \"label sequence models\", \"Viterbi decoding\", \"discriminative log-linear models\"], \"Metric\": [\"error reduction\"], \"Material\": [\"PropBank\"], \"OtherScientificTerm\": [\"joint model\", \"novel features\", \"strong dependencies\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"semantic role labeling\", \"core argument frame\"], \"Method\": [\"independent classifiers\", \"label sequence models\", \"Viterbi decoding\", \"discriminative log-linear models\"], \"Metric\": [\"error reduction\"], \"Material\": [\"PropBank\"], \"OtherScientificTerm\": [\"joint model\", \"novel features\", \"strong dependencies\"], \"Generic\": []}"], "doc_hash": "01b7f7d0bf7a6b7b897d019f45da0d22c44b4971aad9e63664901b200c467da9", "prompt_hash": "3314ad8be38ea95402938d5619e65081697184067c8ec5f20571ba5507fafa52", "target_hash": "ad0c8190b41699e0ac06c2ca89aa485950361c6411c9fb3dd9d5a3d9ec8f0974", "bypass": null}
{"doc_id": 28, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nOne of the major problems one is faced with when decomposing words into their constituent parts is ambiguity: the generation of multiple analyses for one input word, many of which are implausible. In order to deal with ambiguity, the MORphological PArser MORPA is provided with a probabilistic context-free grammar (PCFG), i.e. it combines a 'conventional' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse. Consequently, remaining analyses can be ordered along a scale of plausibility. Test performance data will show that a PCFG yields good results in morphological parsing. MORPA is a fully implemented parser developed for use in a text-to-speech conversion system.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"probabilistic context-free grammar (PCFG)\", \"parser\", \"MORphological PArser MORPA\", \"\\u0027conventional\\u0027 context-free morphological grammar\", \"probability-based scoring function\"], \"Metric\": [], \"OtherScientificTerm\": [\"ungrammatical segmentations\", \"ambiguity\"], \"Task\": [\"text-to-speech conversion system\", \"morphological parsing\", \"generation\", \"parse\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:34"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"probabilistic context-free grammar (PCFG)\", \"parser\", \"MORphological PArser MORPA\", \"\\u0027conventional\\u0027 context-free morphological grammar\", \"probability-based scoring function\"], \"Metric\": [], \"OtherScientificTerm\": [\"ungrammatical segmentations\", \"ambiguity\"], \"Task\": [\"text-to-speech conversion system\", \"morphological parsing\", \"generation\", \"parse\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nOne of the major problems one is faced with when decomposing words into their constituent parts is ambiguity: the generation of multiple analyses for one input word, many of which are implausible. In order to deal with ambiguity, the MORphological PArser MORPA is provided with a probabilistic context-free grammar (PCFG), i.e. it combines a 'conventional' context-free morphological grammar to filter out ungrammatical segmentations with a probability-based scoring function which determines the likelihood of each successful parse. Consequently, remaining analyses can be ordered along a scale of plausibility. Test performance data will show that a PCFG yields good results in morphological parsing. MORPA is a fully implemented parser developed for use in a text-to-speech conversion system.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"decomposing words into their constituent parts\", \"morphological parsing\"], \"Method\": [\"probabilistic context-free grammar\", \"PCFG\", \"conventional context-free morphological grammar\", \"probability-based scoring function\", \"MORPA\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"text-to-speech conversion system\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"decomposing words into their constituent parts\", \"morphological parsing\"], \"Method\": [\"probabilistic context-free grammar\", \"PCFG\", \"conventional context-free morphological grammar\", \"probability-based scoring function\", \"MORPA\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"text-to-speech conversion system\"], \"Generic\": []}"], "doc_hash": "2a0fd3859367b310b09fcfb4f105a518f3c2d25cbd8bf96c066be49ae4bae20b", "prompt_hash": "c2cb98638e900a56bef2a2c53d7f43f40250f1096608da35ac96e90d46105a8b", "target_hash": "edddd829eae3421be081f01372029570e28380d65da79b36a8196fcb00865151", "bypass": null}
{"doc_id": 29, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism: Korean Phonology Structure Grammar (KPSG). The approach of KPSG provides an explicit development model for constructing a computational phonological system: speech recognition and synthesis system. We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach.", "output": "{\"Generic\": [\"approaches\", \"approach\"], \"Material\": [], \"Method\": [\"unification-based grammar formalism\", \"Korean Phonology Structure Grammar (KPSG)\", \"generative phonological approach\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"Korean phonological knowledge base system\", \"phonological system\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:35"}, "target": "{\"Generic\": [\"approaches\", \"approach\"], \"Material\": [], \"Method\": [\"unification-based grammar formalism\", \"Korean Phonology Structure Grammar (KPSG)\", \"generative phonological approach\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"Korean phonological knowledge base system\", \"phonological system\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper describes the framework of a Korean phonological knowledge base system using the unification-based grammar formalism: Korean Phonology Structure Grammar (KPSG). The approach of KPSG provides an explicit development model for constructing a computational phonological system: speech recognition and synthesis system. We show that the proposed approach is more describable than other approaches such as those employing a traditional generative phonological approach.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"speech recognition and synthesis system\"], \"Method\": [\"Korean Phonology Structure Grammar (KPSG)\"], \"Material\": [], \"OtherScientificTerm\": [\"unification-based grammar formalism\", \"explicit development model\", \"computational phonological system\", \"traditional generative phonological approach\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"speech recognition and synthesis system\"], \"Method\": [\"Korean Phonology Structure Grammar (KPSG)\"], \"Material\": [], \"OtherScientificTerm\": [\"unification-based grammar formalism\", \"explicit development model\", \"computational phonological system\", \"traditional generative phonological approach\"], \"Generic\": []}"], "doc_hash": "bb75a32760554d410717ca598322bb2ee628f552824cf41dcba3bcf76c37759d", "prompt_hash": "596ef3c2ec0cbb7486bd0f04711077e1b4e35313c7402a718dddedafcc793de6", "target_hash": "c2f06a956b6c822443b9f6fc379fe5b8e92af97df35f791579474548559d3499", "bypass": null}
{"doc_id": 30, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn some auction domains, there is uncertainty regarding the final availability of the goods being auctioned off. For example, a government may auction off spectrum from its public safety network, but it may need this spectrum back in times of emergency. In such a domain, standard combinatorial auctions perform poorly because they lead to violations of individual rationality (IR), even in expectation, and to very low efficiency. In this paper, we study the design of core-selecting payment rules for such domains. Surprisingly, we show that in this new domain, there does not exist a payment rule with is guaranteed to be ex-post core-selecting. However, we show that by designing rules that are 'execution-contingent,' i.e., by charging payments that are conditioned on the realization of the availability of the goods, we can reduce IR violations. We design two core-selecting rules that always satisfy IR in expectation. To study the performance of our rules we perform a computational Bayes-Nash equilibrium analysis. We show that, in equilibrium, our new rules have better incentives, higher efficiency, and a lower rate of ex-post IR violations than standard core-selecting rules.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"combinatorial auctions\", \"computational Bayes-Nash equilibrium analysis\"], \"Metric\": [\"rate of ex-post IR violations\"], \"OtherScientificTerm\": [\"individual rationality (IR)\", \"violations of individual rationality (IR)\", \"payment rule\", \"core-selecting rules\"], \"Task\": [\"auction domains\", \"design of core-selecting payment rules\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:36"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"combinatorial auctions\", \"computational Bayes-Nash equilibrium analysis\"], \"Metric\": [\"rate of ex-post IR violations\"], \"OtherScientificTerm\": [\"individual rationality (IR)\", \"violations of individual rationality (IR)\", \"payment rule\", \"core-selecting rules\"], \"Task\": [\"auction domains\", \"design of core-selecting payment rules\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn some auction domains, there is uncertainty regarding the final availability of the goods being auctioned off. For example, a government may auction off spectrum from its public safety network, but it may need this spectrum back in times of emergency. In such a domain, standard combinatorial auctions perform poorly because they lead to violations of individual rationality (IR), even in expectation, and to very low efficiency. In this paper, we study the design of core-selecting payment rules for such domains. Surprisingly, we show that in this new domain, there does not exist a payment rule with is guaranteed to be ex-post core-selecting. However, we show that by designing rules that are 'execution-contingent,' i.e., by charging payments that are conditioned on the realization of the availability of the goods, we can reduce IR violations. We design two core-selecting rules that always satisfy IR in expectation. To study the performance of our rules we perform a computational Bayes-Nash equilibrium analysis. We show that, in equilibrium, our new rules have better incentives, higher efficiency, and a lower rate of ex-post IR violations than standard core-selecting rules.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"design of core-selecting payment rules\"], \"Method\": [\"computational Bay-Nash equilibrium analysis\"], \"Metric\": [\"IR violations\", \"efficiency\"], \"Material\": [], \"OtherScientificTerm\": [\"ex-post core-selecting\", \"execution-contingent\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"design of core-selecting payment rules\"], \"Method\": [\"computational Bay-Nash equilibrium analysis\"], \"Metric\": [\"IR violations\", \"efficiency\"], \"Material\": [], \"OtherScientificTerm\": [\"ex-post core-selecting\", \"execution-contingent\"], \"Generic\": []}"], "doc_hash": "0f0b0408dac3c21d2047c38a8d8c95d0aa7ce8c35a46589aebc2f8c80b796e55", "prompt_hash": "dfc130f226d132d763aaed80bbe18f34805dcdd799c923f6652e19a6b0deef53", "target_hash": "8d23b454b4ee62534b4b605fd9e6c4ea25f1aad1f93bca2bf1175ffe663e7c30", "bypass": null}
{"doc_id": 31, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we will describe a search tool for a huge set of ngrams. The tool supports queries with an arbitrary number of wildcards. It takes a fraction of a second for a search, and can provide the fillers of the wildcards. The system runs on a single Linux PC with reasonable size memory (less than 4GB) and disk space (less than 400GB). This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"search tool\"], \"Metric\": [], \"OtherScientificTerm\": [\"disk space\", \"memory\", \"ngrams\"], \"Task\": [\"linguistic knowledge discovery\", \"NLP tasks\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:37"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"search tool\"], \"Metric\": [], \"OtherScientificTerm\": [\"disk space\", \"memory\", \"ngrams\"], \"Task\": [\"linguistic knowledge discovery\", \"NLP tasks\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we will describe a search tool for a huge set of ngrams. The tool supports queries with an arbitrary number of wildcards. It takes a fraction of a second for a search, and can provide the fillers of the wildcards. The system runs on a single Linux PC with reasonable size memory (less than 4GB) and disk space (less than 400GB). This system can be a very useful tool for linguistic knowledge discovery and other NLP tasks.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"linguistic knowledge discovery\", \"NLP tasks\"], \"Method\": [\"search tool\"], \"Material\": [], \"OtherScientificTerm\": [\"huge set of ngrams\", \"wildcards\"]}"]], "filtered_resps": ["{\"Task\": [\"linguistic knowledge discovery\", \"NLP tasks\"], \"Method\": [\"search tool\"], \"Material\": [], \"OtherScientificTerm\": [\"huge set of ngrams\", \"wildcards\"]}"], "doc_hash": "3dc0870c055020022ba2d4f264ea94d19dc428bf7278b705e2fcd7391fe08b33", "prompt_hash": "263def68fa49aa24bf48618a9d0e02fad09128a423509fa7c71fe9374c90c077", "target_hash": "1c02677e34ab474b6cc68a3ade8970a897950259f884ae877ba46a933896d6e4", "bypass": null}
{"doc_id": 32, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nFor intelligent interactive systems to communicate with humans in a natural manner, they must have knowledge about the system users. This paper explores the role of user modeling in such systems. It begins with a characterization of what a user model is and how it can be used. The types of information that a user model may be required to keep about a user are then identified and discussed. User models themselves can vary greatly depending on the requirements of the situation and the implementation, so several dimensions along which they can be classified are presented. Since acquiring the knowledge for a user model is a fundamental problem in user modeling, a section is devoted to this topic. Next, the benefits and costs of implementing a user modeling component for a system are weighed in light of several aspects of the interaction requirements that may be imposed by the system. Finally, the current state of research in user modeling is summarized, and future research topics that must be addressed in order to achieve powerful, general user modeling systems are assessed.", "output": "{\"Generic\": [\"system\"], \"Material\": [], \"Method\": [\"user model\", \"intelligent interactive systems\", \"user modeling component\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"user modeling\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:38"}, "target": "{\"Generic\": [\"system\"], \"Material\": [], \"Method\": [\"user model\", \"intelligent interactive systems\", \"user modeling component\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"user modeling\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nFor intelligent interactive systems to communicate with humans in a natural manner, they must have knowledge about the system users. This paper explores the role of user modeling in such systems. It begins with a characterization of what a user model is and how it can be used. The types of information that a user model may be required to keep about a user are then identified and discussed. User models themselves can vary greatly depending on the requirements of the situation and the implementation, so several dimensions along which they can be classified are presented. Since acquiring the knowledge for a user model is a fundamental problem in user modeling, a section is devoted to this topic. Next, the benefits and costs of implementing a user modeling component for a system are weighed in light of several aspects of the interaction requirements that may be imposed by the system. Finally, the current state of research in user modeling is summarized, and future research topics that must be addressed in order to achieve powerful, general user modeling systems are assessed.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"user model\", \"user modeling\", \"interaction requirements\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"user model\", \"user modeling\", \"interaction requirements\"], \"Generic\": []}"], "doc_hash": "02b84cd20962be95079756ffe406fa9e29dcad539ce00f280c1cf0914fee5135", "prompt_hash": "b8555faa70be1b01831ca05554c916020770b1002eb4250d68225cb15e87afd2", "target_hash": "d118a1e78efeec8f7977e718ed921487c6949f3d72cf095351be8989a9226c35", "bypass": null}
{"doc_id": 33, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nInformation extraction techniques automatically create structured databases from unstructured data sources, such as the Web or newswire documents. Despite the successes of these systems, accuracy will always be imperfect. For many reasons, it is highly desirable to accurately estimate the confidence the system has in the correctness of each extracted field. The information extraction system we evaluate is based on a linear-chain conditional random field (CRF), a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary, overlapping features of the input in a Markov model. We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records, obtaining an average precision of 98% for retrieving correct fields and 87% for multi-field records.", "output": "{\"Generic\": [\"techniques\", \"input\", \"extracted fields\"], \"Material\": [\"Web\", \"multi-field records\", \"unstructured data sources\", \"newswire documents\", \"structured databases\"], \"Method\": [\"linear-chain conditional random field (CRF)\", \"Markov model\", \"Information extraction techniques\", \"probabilistic model\"], \"Metric\": [\"average precision\", \"accuracy\"], \"OtherScientificTerm\": [\"arbitrary , overlapping features\"], \"Task\": [\"information extraction tasks\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:39"}, "target": "{\"Generic\": [\"techniques\", \"input\", \"extracted fields\"], \"Material\": [\"Web\", \"multi-field records\", \"unstructured data sources\", \"newswire documents\", \"structured databases\"], \"Method\": [\"linear-chain conditional random field (CRF)\", \"Markov model\", \"Information extraction techniques\", \"probabilistic model\"], \"Metric\": [\"average precision\", \"accuracy\"], \"OtherScientificTerm\": [\"arbitrary , overlapping features\"], \"Task\": [\"information extraction tasks\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nInformation extraction techniques automatically create structured databases from unstructured data sources, such as the Web or newswire documents. Despite the successes of these systems, accuracy will always be imperfect. For many reasons, it is highly desirable to accurately estimate the confidence the system has in the correctness of each extracted field. The information extraction system we evaluate is based on a linear-chain conditional random field (CRF), a probabilistic model which has performed well on information extraction tasks because of its ability to capture arbitrary, overlapping features of the input in a Markov model. We implement several techniques to estimate the confidence of both extracted fields and entire multi-field records, obtaining an average precision of 98% for retrieving correct fields and 87% for multi-field records.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"information extraction\", \"information extraction tasks\"], \"Method\": [\"linear-chain conditional random field (CRF)\", \"probabilistic model\"], \"Metric\": [\"average precision\"], \"Material\": [], \"OtherScientificTerm\": [\"Markov model\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"information extraction\", \"information extraction tasks\"], \"Method\": [\"linear-chain conditional random field (CRF)\", \"probabilistic model\"], \"Metric\": [\"average precision\"], \"Material\": [], \"OtherScientificTerm\": [\"Markov model\"], \"Generic\": []}"], "doc_hash": "455b7123999471e6858de8fe1c69f63399f16519ced316c6e895d0a9a606ae7d", "prompt_hash": "6b0907836d02e973a1c4be5aaf301d7ec59b2eefdade6704a7562c26ad27db65", "target_hash": "4cf380a8ebd986c1fd5898fb97170632edc2eb466d2eb4557c7a22b469348cde", "bypass": null}
{"doc_id": 34, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora. This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus. Our approach is based on the idea that one person tends to use one expression for one meaning. According to our assumption, most of the words with similar context features in each author 's corpus tend not to be synonymous expressions. Our proposed method improves the accuracy of our term aggregation system, showing that our approach is successful.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"term aggregation system\", \"text mining method\"], \"Metric\": [\"accuracy\"], \"OtherScientificTerm\": [\"similar context features\", \"synonymous expressions\", \"distributional hypothesis\"], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:4"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"term aggregation system\", \"text mining method\"], \"Metric\": [\"accuracy\"], \"OtherScientificTerm\": [\"similar context features\", \"synonymous expressions\", \"distributional hypothesis\"], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a text mining method for finding synonymous expressions based on the distributional hypothesis in a set of coherent corpora. This paper proposes a new methodology to improve the accuracy of a term aggregation system using each author 's text as a coherent corpus. Our approach is based on the idea that one person tends to use one expression for one meaning. According to our assumption, most of the words with similar context features in each author 's corpus tend not to be synonymous expressions. Our proposed method improves the accuracy of our term aggregation system, showing that our approach is successful.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"term aggregation system\"], \"Method\": [\"text mining method\", \"proposes a new methodology\"], \"Material\": [], \"OtherScientificTerm\": [\"distributional hypothesis\", \"coherent corpora\", \"context features\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"term aggregation system\"], \"Method\": [\"text mining method\", \"proposes a new methodology\"], \"Material\": [], \"OtherScientificTerm\": [\"distributional hypothesis\", \"coherent corpora\", \"context features\"], \"Generic\": []}"], "doc_hash": "455c1487501f6b16888ef5db502454808f39a81bab6516f1ebea460d5fd1b19f", "prompt_hash": "187881030e80d51bad6c050bc515344c6d1d76fa8e963c57cbcc80ec88702536", "target_hash": "eaa23e64ca628f832eea4dcd473e8378dd7089fb7689f2e83fdcea286c3405dc", "bypass": null}
{"doc_id": 35, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries. We consider the case of multi-document summarization, where the input documents are in Arabic, and the output summary is in English. Typically, information that makes it to a summary appears in many different lexical-syntactic forms in the input documents. Further, the use of multiple machine translation systems provides yet more redundancy, yielding different ways to realize that information in English. We demonstrate how errors in the machine translations of the input Arabic documents can be corrected by identifying and generating from such redundancy, focusing on noun phrases.", "output": "{\"Generic\": [], \"Material\": [\"Arabic\", \"Arabic documents\", \"English\"], \"Method\": [\"machine translation systems\"], \"Metric\": [], \"OtherScientificTerm\": [\"information redundancy in multilingual input\", \"lexical-syntactic forms\"], \"Task\": [\"machine translation\", \"multi-document summarization\", \"multilingual summaries\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:40"}, "target": "{\"Generic\": [], \"Material\": [\"Arabic\", \"Arabic documents\", \"English\"], \"Method\": [\"machine translation systems\"], \"Metric\": [], \"OtherScientificTerm\": [\"information redundancy in multilingual input\", \"lexical-syntactic forms\"], \"Task\": [\"machine translation\", \"multi-document summarization\", \"multilingual summaries\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we use the information redundancy in multilingual input to correct errors in machine translation and thus improve the quality of multilingual summaries. We consider the case of multi-document summarization, where the input documents are in Arabic, and the output summary is in English. Typically, information that makes it to a summary appears in many different lexical-syntactic forms in the input documents. Further, the use of multiple machine translation systems provides yet more redundancy, yielding different ways to realize that information in English. We demonstrate how errors in the machine translations of the input Arabic documents can be corrected by identifying and generating from such redundancy, focusing on noun phrases.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"multilingual summaries\", \"multi-document summarization\"], \"Method\": [], \"Material\": [\"Arabic\", \"English\", \"machine translation systems\"], \"OtherScientificTerm\": [\"information redundancy\", \"lexico-syntactic forms\", \"noun phrases\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"multilingual summaries\", \"multi-document summarization\"], \"Method\": [], \"Material\": [\"Arabic\", \"English\", \"machine translation systems\"], \"OtherScientificTerm\": [\"information redundancy\", \"lexico-syntactic forms\", \"noun phrases\"], \"Generic\": []}"], "doc_hash": "2339ec8711962a024bae38db26d5ccf150e15efab5e82148baaec071da5ef77b", "prompt_hash": "5917fb40df2097633319b2a504f9d3156a4d82791c0e17142188249c45ed0d5c", "target_hash": "58a32a3315f18f5263efaf7ea0a04b58e43fcbc005adcf37f238155175eeb3e2", "bypass": null}
{"doc_id": 36, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we propose a new approach to generate oriented object proposals (OOPs) to reduce the detection error caused by various orientations of the object. To this end, we propose to efficiently locate object regions according to pixelwise object probability, rather than measuring the objectness from a set of sampled windows. We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes (i.e., sizes and orientations) can be produced by locating the local maximum likelihoods. The new approach has three main advantages. First, it helps the object detector handle objects of different orientations. Second, as the shapes of the proposals may vary to fit the objects, the resulting proposals are tighter than the sampling windows with fixed sizes. Third, it avoids massive window sampling, and thereby reducing the number of proposals while maintaining a high recall. Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods. Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios. Generating OOPs is very fast and takes only 0.5 s per image.", "output": "{\"Generic\": [\"state-of-the-art fast methods\", \"approach\"], \"Material\": [\"general scenarios\", \"object rotation scenarios\", \"PASCAL VOC 2007 dataset\"], \"Method\": [\"class-specific object detector\", \"proposal generation methods\", \"massive window sampling\", \"OOP\", \"object detector\"], \"Metric\": [\"recall\", \"detection error\"], \"OtherScientificTerm\": [\"object regions\", \"local maximum likelihoods\", \"orientations\", \"object proposals\", \"shapes of the proposals\", \"pixelwise object probability\", \"shapes\", \"sizes\", \"number of proposals\", \"objectness\", \"sampling windows\", \"rotation invariant property\", \"orientations of the object\"], \"Task\": [\"oriented object proposals (OOPs)\", \"proposal generation problem\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:41"}, "target": "{\"Generic\": [\"state-of-the-art fast methods\", \"approach\"], \"Material\": [\"general scenarios\", \"object rotation scenarios\", \"PASCAL VOC 2007 dataset\"], \"Method\": [\"class-specific object detector\", \"proposal generation methods\", \"massive window sampling\", \"OOP\", \"object detector\"], \"Metric\": [\"recall\", \"detection error\"], \"OtherScientificTerm\": [\"object regions\", \"local maximum likelihoods\", \"orientations\", \"object proposals\", \"shapes of the proposals\", \"pixelwise object probability\", \"shapes\", \"sizes\", \"number of proposals\", \"objectness\", \"sampling windows\", \"rotation invariant property\", \"orientations of the object\"], \"Task\": [\"oriented object proposals (OOPs)\", \"proposal generation problem\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper, we propose a new approach to generate oriented object proposals (OOPs) to reduce the detection error caused by various orientations of the object. To this end, we propose to efficiently locate object regions according to pixelwise object probability, rather than measuring the objectness from a set of sampled windows. We formulate the proposal generation problem as a generative proba-bilistic model such that object proposals of different shapes (i.e., sizes and orientations) can be produced by locating the local maximum likelihoods. The new approach has three main advantages. First, it helps the object detector handle objects of different orientations. Second, as the shapes of the proposals may vary to fit the objects, the resulting proposals are tighter than the sampling windows with fixed sizes. Third, it avoids massive window sampling, and thereby reducing the number of proposals while maintaining a high recall. Experiments on the PASCAL VOC 2007 dataset show that the proposed OOP outperforms the state-of-the-art fast methods. Further experiments show that the rotation invariant property helps a class-specific object detector achieve better performance than the state-of-the-art proposal generation methods in either object rotation scenarios or general scenarios. Generating OOPs is very fast and takes only 0.5 s per image.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"generate oriented object proposals\"], \"Method\": [\"generative probabilistic model\"], \"Metric\": [\"high recall\"], \"Material\": [], \"OtherScientificTerm\": [\"local maximum likelihoods\", \"rotation invariant property\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"generate oriented object proposals\"], \"Method\": [\"generative probabilistic model\"], \"Metric\": [\"high recall\"], \"Material\": [], \"OtherScientificTerm\": [\"local maximum likelihoods\", \"rotation invariant property\"], \"Generic\": []}"], "doc_hash": "db43b9ac0e19e7ab7a436a37377bf8dbcccf6a6e94d61b65495b65e9aa6240f6", "prompt_hash": "07f7d324404b0cb6b7f9adaba0c319f4c0078742cd678e715342e8212958df63", "target_hash": "eb6fe9b8613ec3bdaaf2ecd08e41200a94845a39291bc4addb68033eecec98ec", "bypass": null}
{"doc_id": 37, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system: non-monotonic reasoning, implicit reference resolution, and database query paraphrase. In addition, we discuss the results of the February 1992 ATIS benchmark tests. We describe a variation on the standard evaluation metric which provides a more tightly controlled measure of progress. Finally, we briefly describe an experiment which we have done in extending the n-best speech/language integration architecture to improving OCR accuracy.", "output": "{\"Generic\": [\"domain-independent capabilities\"], \"Material\": [\"February 1992 ATIS benchmark tests\"], \"Method\": [\"Paramax spoken language understanding system\", \"n-best speech/language integration architecture\"], \"Metric\": [\"OCR accuracy\"], \"OtherScientificTerm\": [], \"Task\": [\"implicit reference resolution\", \"database query paraphrase\", \"non-monotonic reasoning\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:42"}, "target": "{\"Generic\": [\"domain-independent capabilities\"], \"Material\": [\"February 1992 ATIS benchmark tests\"], \"Method\": [\"Paramax spoken language understanding system\", \"n-best speech/language integration architecture\"], \"Metric\": [\"OCR accuracy\"], \"OtherScientificTerm\": [], \"Task\": [\"implicit reference resolution\", \"database query paraphrase\", \"non-monotonic reasoning\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper describes three relatively domain-independent capabilities recently added to the Paramax spoken language understanding system: non-monotonic reasoning, implicit reference resolution, and database query paraphrase. In addition, we discuss the results of the February 1992 ATIS benchmark tests. We describe a variation on the standard evaluation metric which provides a more tightly controlled measure of progress. Finally, we briefly describe an experiment which we have done in extending the n-best speech/language integration architecture to improving OCR accuracy.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"spoken language understanding system\", \"ATIS benchmark tests\", \"speech/language integration architecture\"], \"Method\": [\"non-monotonic reasoning\", \"implicit reference resolution\", \"database query paraphrase\", \"n-best speech/language integration architecture\"], \"Metric\": [\"standard evaluation metric\"], \"Material\": [], \"OtherScientificTerm\": [\"OCR accuracy\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"spoken language understanding system\", \"ATIS benchmark tests\", \"speech/language integration architecture\"], \"Method\": [\"non-monotonic reasoning\", \"implicit reference resolution\", \"database query paraphrase\", \"n-best speech/language integration architecture\"], \"Metric\": [\"standard evaluation metric\"], \"Material\": [], \"OtherScientificTerm\": [\"OCR accuracy\"], \"Generic\": []}"], "doc_hash": "f90814c8cadcb09bd277668dd5d93c5df7ff33c8bf2859c75f066e0ca473a2ea", "prompt_hash": "c94b78d24a66aeebba793b4579a3f6b2c88b343ef057063e9f5326ba67473013", "target_hash": "981e5d50b24a80b63faea10d05e42b850f232919a196342f18d934180063a451", "bypass": null}
{"doc_id": 38, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images. This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based image retrieval application. We introduce a new database of 1,432 sketch-photo pairs from two categories with 32,000 fine-grained triplet ranking annotations. We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data. Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks.", "output": "{\"Generic\": [], \"Material\": [\"annotated cross-domain sketch-photo datasets\", \"insufficient fine-grained training data\"], \"Method\": [\"machine learning techniques\", \"deep triplet-ranking model\", \"data augmentation\", \"deep networks\", \"staged pre-training strategy\"], \"Metric\": [], \"OtherScientificTerm\": [\"free-hand human sketches\", \"fine-grained triplet ranking annotations\", \"free-hand (finger) sketches\", \"data sufficiency\", \"over-fitting avoidance\", \"visual comparisons\"], \"Task\": [\"fine-grained sketch-based image retrieval (SBIR)\", \"instance-level SBIR\", \"instance-level retrieval of images\", \"sketch-based image retrieval application\", \"fine-grained matching\", \"fine-grained cross-domain ranking tasks\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:43"}, "target": "{\"Generic\": [], \"Material\": [\"annotated cross-domain sketch-photo datasets\", \"insufficient fine-grained training data\"], \"Method\": [\"machine learning techniques\", \"deep triplet-ranking model\", \"data augmentation\", \"deep networks\", \"staged pre-training strategy\"], \"Metric\": [], \"OtherScientificTerm\": [\"free-hand human sketches\", \"fine-grained triplet ranking annotations\", \"free-hand (finger) sketches\", \"data sufficiency\", \"over-fitting avoidance\", \"visual comparisons\"], \"Task\": [\"fine-grained sketch-based image retrieval (SBIR)\", \"instance-level SBIR\", \"instance-level retrieval of images\", \"sketch-based image retrieval application\", \"fine-grained matching\", \"fine-grained cross-domain ranking tasks\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe investigate the problem of fine-grained sketch-based image retrieval (SBIR), where free-hand human sketches are used as queries to perform instance-level retrieval of images. This is an extremely challenging task because (i) visual comparisons not only need to be fine-grained but also executed cross-domain, (ii) free-hand (finger) sketches are highly abstract, making fine-grained matching harder, and most importantly (iii) annotated cross-domain sketch-photo datasets required for training are scarce, challenging many state-of-the-art machine learning techniques. In this paper, for the first time, we address all these challenges, providing a step towards the capabilities that would underpin a commercial sketch-based image retrieval application. We introduce a new database of 1,432 sketch-photo pairs from two categories with 32,000 fine-grained triplet ranking annotations. We then develop a deep triplet-ranking model for instance-level SBIR with a novel data augmentation and staged pre-training strategy to alleviate the issue of insufficient fine-grained training data. Extensive experiments are carried out to contribute a variety of insights into the challenges of data sufficiency and over-fitting avoidance when training deep networks for fine-grained cross-domain ranking tasks.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"fine-grained sketch-based image retrieval\", \"instance-level retrieval of images\"], \"Method\": [\"deep triplet-ranking model\", \"staged pre-training strategy\", \"data augmentation\"], \"Material\": [\"1,432 sketch-photo pairs\", \"CoNLL\"], \"OtherScientificTerm\": [\"triplet ranking annotations\", \"fine-grained triplet ranking annotations\", \"deep networks\", \"cross-domain ranking tasks\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"fine-grained sketch-based image retrieval\", \"instance-level retrieval of images\"], \"Method\": [\"deep triplet-ranking model\", \"staged pre-training strategy\", \"data augmentation\"], \"Material\": [\"1,432 sketch-photo pairs\", \"CoNLL\"], \"OtherScientificTerm\": [\"triplet ranking annotations\", \"fine-grained triplet ranking annotations\", \"deep networks\", \"cross-domain ranking tasks\"], \"Generic\": []}"], "doc_hash": "5000e3f7c27fdebf3d508271718badf52e481373d33a4877a3f8b62d87047391", "prompt_hash": "1635ce20899ed3808eb616753aac00fc968942a46d918d2f73dad2ed871af915", "target_hash": "6f9b7015653297886b7b29f67d8660fe3cac72f8cd486fa3c682a115ff00e52a", "bypass": null}
{"doc_id": 39, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we target at generating generic action proposals in unconstrained videos. Each action proposal corresponds to a temporal series of spatial bounding boxes, i.e., a spatio-temporal video tube, which has a good potential to locate one human action. Assuming each action is performed by a human with meaningful motion, both appearance and motion cues are utilized to measure the ac-tionness of the video tubes. After picking those spatiotem-poral paths of high actionness scores, our action proposal generation is formulated as a maximum set coverage problem, where greedy search is performed to select a set of action proposals that can maximize the overall actionness score. Compared with existing action proposal approaches, our action proposals do not rely on video segmentation and can be generated in nearly real-time. Experimental results on two challenging datasets, MSRII and UCF 101, validate the superior performance of our action proposals as well as competitive results on action detection and search.", "output": "{\"Generic\": [\"datasets\"], \"Material\": [\"unconstrained videos\", \"video tubes\", \"UCF 101\", \"MSRII\"], \"Method\": [\"action proposal approaches\", \"greedy search\", \"video segmentation\"], \"Metric\": [\"actionness scores\", \"actionness score\", \"ac-tionness\"], \"OtherScientificTerm\": [\"generic action proposals\", \"appearance and motion cues\", \"action proposals\", \"spatio-temporal video tube\", \"human action\", \"action proposal\", \"temporal series of spatial bounding boxes\"], \"Task\": [\"maximum set coverage problem\", \"action proposal generation\", \"action detection and search\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:44"}, "target": "{\"Generic\": [\"datasets\"], \"Material\": [\"unconstrained videos\", \"video tubes\", \"UCF 101\", \"MSRII\"], \"Method\": [\"action proposal approaches\", \"greedy search\", \"video segmentation\"], \"Metric\": [\"actionness scores\", \"actionness score\", \"ac-tionness\"], \"OtherScientificTerm\": [\"generic action proposals\", \"appearance and motion cues\", \"action proposals\", \"spatio-temporal video tube\", \"human action\", \"action proposal\", \"temporal series of spatial bounding boxes\"], \"Task\": [\"maximum set coverage problem\", \"action proposal generation\", \"action detection and search\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this paper we target at generating generic action proposals in unconstrained videos. Each action proposal corresponds to a temporal series of spatial bounding boxes, i.e., a spatio-temporal video tube, which has a good potential to locate one human action. Assuming each action is performed by a human with meaningful motion, both appearance and motion cues are utilized to measure the ac-tionness of the video tubes. After picking those spatiotem-poral paths of high actionness scores, our action proposal generation is formulated as a maximum set coverage problem, where greedy search is performed to select a set of action proposals that can maximize the overall actionness score. Compared with existing action proposal approaches, our action proposals do not rely on video segmentation and can be generated in nearly real-time. Experimental results on two challenging datasets, MSRII and UCF 101, validate the superior performance of our action proposals as well as competitive results on action detection and search.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"generating generic action proposals in unconstrained videos\", \"action proposal generation\"], \"Method\": [\"greedy search\", \"maximum set coverage problem\"], \"Material\": [], \"OtherScientificTerm\": [\"spatio-temporal video tube\", \"actionness score\", \"video segmentation\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"generating generic action proposals in unconstrained videos\", \"action proposal generation\"], \"Method\": [\"greedy search\", \"maximum set coverage problem\"], \"Material\": [], \"OtherScientificTerm\": [\"spatio-temporal video tube\", \"actionness score\", \"video segmentation\"], \"Generic\": []}"], "doc_hash": "4eb8b7ff523227e5f4464b85e95487cf1d9aab200dfcb6f8c63c095e29f42476", "prompt_hash": "16d3413351a55f5ea192e9d6f4a713248d7338113deb01111d004b6cc19a39f9", "target_hash": "952af05929075ed2c89bf0974ca85f71047c17d66fe9831651dff7b7119868ab", "bypass": null}
{"doc_id": 40, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper reports recent research into methods for creating natural language text. A new processing paradigm called Fragment-and-Compose has been created and an experimental system implemented in it. The knowledge to be expressed in text is first divided into small propositional units, which are then composed into appropriate combinations and converted into text. KDS (Knowledge Delivery System), which embodies this paradigm, has distinct parts devoted to creation of the propositional units, to organization of the text, to prevention of excess redundancy, to creation of combinations of units, to evaluation of these combinations as potential sentences, to selection of the best among competing combinations, and to creation of the final text. The Fragment-and-Compose paradigm and the computational methods of KDS are described.", "output": "{\"Generic\": [\"methods\", \"computational methods\"], \"Material\": [], \"Method\": [\"KDS (Knowledge Delivery System)\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"creating natural language text\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:45"}, "target": "{\"Generic\": [\"methods\", \"computational methods\"], \"Material\": [], \"Method\": [\"KDS (Knowledge Delivery System)\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": [\"creating natural language text\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper reports recent research into methods for creating natural language text. A new processing paradigm called Fragment-and-Compose has been created and an experimental system implemented in it. The knowledge to be expressed in text is first divided into small propositional units, which are then composed into appropriate combinations and converted into text. KDS (Knowledge Delivery System), which embodies this paradigm, has distinct parts devoted to creation of the propositional units, to organization of the text, to prevention of excess redundancy, to creation of combinations of units, to evaluation of these combinations as potential sentences, to selection of the best among competing combinations, and to creation of the final text. The Fragment-and-Compose paradigm and the computational methods of KDS are described.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"natural language text\"], \"Method\": [\"Fragment-and-Compose\", \"KDS\"], \"Material\": [], \"OtherScientificTerm\": [\"propositional units\", \"combinations\", \"Knowledge Delivery System\", \"excess redundancy\", \"potential sentences\", \"final text\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"natural language text\"], \"Method\": [\"Fragment-and-Compose\", \"KDS\"], \"Material\": [], \"OtherScientificTerm\": [\"propositional units\", \"combinations\", \"Knowledge Delivery System\", \"excess redundancy\", \"potential sentences\", \"final text\"], \"Generic\": []}"], "doc_hash": "191854b317f6c47fbc96dc818774cc97abcb5c3e5e75c1cc4f8f09f15ce51e2e", "prompt_hash": "ae9ce08953690a0d027c7c1967dd10e038a1f14aa6f7f7c161b7a0d98aa7b457", "target_hash": "8505a20ea5abb55f30b5980e2764d024881c72ae93535aad5dc257228da16eab", "bypass": null}
{"doc_id": 41, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful. The hypothesis under examination is that useful terms tend to be more similar to each other than to other query terms. Preliminary experiments with similarities computed using first-order and second-order co-occurrence seem to confirm the hypothesis. Term similarities could then be used for determining which query terms are useful and best reflect the user 's information need. A possible application would be to use this source of evidence for tuning the weights of the query terms.", "output": "{\"Generic\": [\"query terms\", \"useful terms\", \"those\", \"similarities\"], \"Material\": [], \"Method\": [], \"Metric\": [], \"OtherScientificTerm\": [\"first-order and second-order co-occurrence\", \"co-occurrence similarities\"], \"Task\": [\"retrieval\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:46"}, "target": "{\"Generic\": [\"query terms\", \"useful terms\", \"those\", \"similarities\"], \"Material\": [], \"Method\": [], \"Metric\": [], \"OtherScientificTerm\": [\"first-order and second-order co-occurrence\", \"co-occurrence similarities\"], \"Task\": [\"retrieval\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nThis paper explores the issue of using different co-occurrence similarities between terms for separating query terms that are useful for retrieval from those that are harmful. The hypothesis under examination is that useful terms tend to be more similar to each other than to other query terms. Preliminary experiments with similarities computed using first-order and second-order co-occurrence seem to confirm the hypothesis. Term similarities could then be used for determining which query terms are useful and best reflect the user 's information need. A possible application would be to use this source of evidence for tuning the weights of the query terms.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"separating query terms that are useful for retrieval from those that are harmful\", \"determining which query terms are useful and best reflect the user's information need\"], \"Method\": [\"similarities computed using first-order and second-order co-occurrence\"], \"Material\": [], \"OtherScientificTerm\": [\"co-occurrence similarities\", \"useful terms\", \"harmful terms\", \"user's information need\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"separating query terms that are useful for retrieval from those that are harmful\", \"determining which query terms are useful and best reflect the user's information need\"], \"Method\": [\"similarities computed using first-order and second-order co-occurrence\"], \"Material\": [], \"OtherScientificTerm\": [\"co-occurrence similarities\", \"useful terms\", \"harmful terms\", \"user's information need\"], \"Generic\": []}"], "doc_hash": "d08844766c89375e2ae9a15e4792e7be9fa22d881f7daa72184c70e2003e018a", "prompt_hash": "ab4b2ab7149d8862023656f7b0f7d20e1ec2cbd8819fe1f0c944ff804c609277", "target_hash": "2c0583403ab7edb0bc2e9bc031febcb2f769c98cdbf79b8dbefed43d3ac1d014", "bypass": null}
{"doc_id": 42, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems.", "output": "{\"Generic\": [\"means\"], \"Material\": [], \"Method\": [\"phrase-based translation models\", \"word-based models\", \"heuristic learning of phrase translations\", \"high-accuracy word-level alignment models\", \"word-based alignments\", \"lexical weighting of phrase translations\", \"phrase-based translation model\", \"decoding algorithm\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:47"}, "target": "{\"Generic\": [\"means\"], \"Material\": [], \"Method\": [\"phrase-based translation models\", \"word-based models\", \"heuristic learning of phrase translations\", \"high-accuracy word-level alignment models\", \"word-based alignments\", \"lexical weighting of phrase translations\", \"phrase-based translation model\", \"decoding algorithm\"], \"Metric\": [], \"OtherScientificTerm\": [], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models. Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models. Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations. Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance. Learning only syntactically motivated phrases degrades the performance of our systems.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"phrase-based translation model\", \"decoding algorithm\", \"phrase-based translation models\", \"word-based models\", \"phrase translations\", \"lexical weighting of phrase translations\", \"syntactically motivated phrases\"], \"Method\": [\"heuristic learning of phrase translations from word-based alignments\", \"learning phrases from high-accuracy word-level alignment models\"], \"Material\": [], \"OtherScientificTerm\": [\"phrase-based models\", \"word-based models\", \"performance\", \"alignment models\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"phrase-based translation model\", \"decoding algorithm\", \"phrase-based translation models\", \"word-based models\", \"phrase translations\", \"lexical weighting of phrase translations\", \"syntactically motivated phrases\"], \"Method\": [\"heuristic learning of phrase translations from word-based alignments\", \"learning phrases from high-accuracy word-level alignment models\"], \"Material\": [], \"OtherScientificTerm\": [\"phrase-based models\", \"word-based models\", \"performance\", \"alignment models\"], \"Generic\": []}"], "doc_hash": "53490901cd5e7ccd7bb1fb2662db49e0b01812dc196f869a4f23572015c28a27", "prompt_hash": "d08823bd6a4a206922b4b669c060ba24a94f71df841fd7633f7cb94ddc71f21b", "target_hash": "ac8db586feaabcdf8074790b295a17c4549f1d2dcb4718e4db5fb28f327c2686", "bypass": null}
{"doc_id": 43, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nColor is known to be highly discriminative for many object recognition tasks, but is difficult to infer from uncontrolled images in which the illuminant is not known. Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images, but their output depends significantly on the background scene. In many recognition and retrieval applications, we have access to image sets that contain multiple views of the same object in different environments; we show in this paper that correspondences between these images provide important constraints that can improve color constancy. We introduce the multi-view color constancy problem, and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images. The method can exploit image correspondences obtained by various alignment techniques, and we show examples based on matching local region features. Our results show that multi-view constraints can significantly improve estimates of both scene illuminants and object color (surface reflectance) when compared to a baseline single-view method.", "output": "{\"Generic\": [\"method\", \"methods\"], \"Material\": [\"uncontrolled images\", \"uncalibrated images\"], \"Method\": [\"surface re-flectance estimates\", \"alignment techniques\", \"baseline single-view method\"], \"Metric\": [], \"OtherScientificTerm\": [\"illuminants\", \"surface properties\", \"multi-view constraints\", \"matching local region features\", \"background scene\", \"illuminant\", \"image correspondences\"], \"Task\": [\"color constancy\", \"recognition and retrieval applications\", \"estimates of underlying surface re-flectance\", \"estimates of both scene illuminants and object color (surface reflectance)\", \"multi-view color constancy problem\", \"object recognition tasks\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:48"}, "target": "{\"Generic\": [\"method\", \"methods\"], \"Material\": [\"uncontrolled images\", \"uncalibrated images\"], \"Method\": [\"surface re-flectance estimates\", \"alignment techniques\", \"baseline single-view method\"], \"Metric\": [], \"OtherScientificTerm\": [\"illuminants\", \"surface properties\", \"multi-view constraints\", \"matching local region features\", \"background scene\", \"illuminant\", \"image correspondences\"], \"Task\": [\"color constancy\", \"recognition and retrieval applications\", \"estimates of underlying surface re-flectance\", \"estimates of both scene illuminants and object color (surface reflectance)\", \"multi-view color constancy problem\", \"object recognition tasks\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nColor is known to be highly discriminative for many object recognition tasks, but is difficult to infer from uncontrolled images in which the illuminant is not known. Traditional methods for color constancy can improve surface re-flectance estimates from such uncalibrated images, but their output depends significantly on the background scene. In many recognition and retrieval applications, we have access to image sets that contain multiple views of the same object in different environments; we show in this paper that correspondences between these images provide important constraints that can improve color constancy. We introduce the multi-view color constancy problem, and present a method to recover estimates of underlying surface re-flectance based on joint estimation of these surface properties and the illuminants present in multiple images. The method can exploit image correspondences obtained by various alignment techniques, and we show examples based on matching local region features. Our results show that multi-view constraints can significantly improve estimates of both scene illuminants and object color (surface reflectance) when compared to a baseline single-view method.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"object recognition\", \"image retrieval\"], \"Method\": [\"multi-view color constancy\", \"joint estimation\", \"alignment techniques\", \"matching local region features\"], \"Material\": [], \"OtherScientificTerm\": [\"surface re-flectance\", \"illuminants\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"object recognition\", \"image retrieval\"], \"Method\": [\"multi-view color constancy\", \"joint estimation\", \"alignment techniques\", \"matching local region features\"], \"Material\": [], \"OtherScientificTerm\": [\"surface re-flectance\", \"illuminants\"], \"Generic\": []}"], "doc_hash": "ad12762d76c9637b7db7b99aa19ff29588dafc2ebc81b5792bb2d70cd975f90e", "prompt_hash": "5e555dc51458cb839c86120e2cfc8e5cb152520d90b4faad12abf32ea60bc202", "target_hash": "f93266e4774c801c0dacc2acf444d4d36654659bf077f70d705d8156001483b7", "bypass": null}
{"doc_id": 44, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe describe a dialogue system that works with its interlocutor to identify objects. Our contributions include a concise, modular architecture with reversible processes of understanding and generation, an information-state model of reference, and flexible links between semantics and collaborative problem solving.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"information-state model of reference\", \"concise , modular architecture\", \"dialogue system\"], \"Metric\": [], \"OtherScientificTerm\": [\"semantics\"], \"Task\": [\"collaborative problem solving\", \"generation\", \"understanding\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:49"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"information-state model of reference\", \"concise , modular architecture\", \"dialogue system\"], \"Metric\": [], \"OtherScientificTerm\": [\"semantics\"], \"Task\": [\"collaborative problem solving\", \"generation\", \"understanding\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe describe a dialogue system that works with its interlocutor to identify objects. Our contributions include a concise, modular architecture with reversible processes of understanding and generation, an information-state model of reference, and flexible links between semantics and collaborative problem solving.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"dialogue system\"], \"Method\": [\"concise, modular architecture\", \"information-state model of reference\", \"flexible links between semantics and collaborative problem solving\"], \"Material\": [], \"OtherScientificTerm\": [\"reversible processes of understanding and generation\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"dialogue system\"], \"Method\": [\"concise, modular architecture\", \"information-state model of reference\", \"flexible links between semantics and collaborative problem solving\"], \"Material\": [], \"OtherScientificTerm\": [\"reversible processes of understanding and generation\"], \"Generic\": []}"], "doc_hash": "0efa819feed257404234dc26501c71cb435c449da446cf517e3172979b3f2fbc", "prompt_hash": "1fa5e7c07373547d726271535311ffbdd56af63959c02568086415cb410e9673", "target_hash": "85cfbab42fc3247b519fc543c2b38cee1d36e6913aa39faedf7cce04f9843300", "bypass": null}
{"doc_id": 45, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this work, we present a technique for robust estimation, which by explicitly incorporating the inherent uncertainty of the estimation procedure, results in a more efficient robust estimation algorithm. In addition, we build on recent work in randomized model verification, and use this to characterize the ` non-randomness ' of a solution. The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques, while requiring no prior information to guide the sampling process. In particular, our algorithm requires, on average, 3-10 times fewer samples than standard RANSAC, which is in close agreement with theoretical predictions. The efficiency of the algorithm is demonstrated on a selection of geometric estimation problems.", "output": "{\"Generic\": [\"strategies\", \"technique\"], \"Material\": [], \"Method\": [\"efficient robust estimation algorithm\", \"RANSAC techniques\"], \"Metric\": [], \"OtherScientificTerm\": [\"prior information\", \"inherent uncertainty of the estimation procedure\", \"theoretical predictions\", \"sampling process\"], \"Task\": [\"geometric estimation problems\", \"robust estimation\", \"randomized model verification\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:5"}, "target": "{\"Generic\": [\"strategies\", \"technique\"], \"Material\": [], \"Method\": [\"efficient robust estimation algorithm\", \"RANSAC techniques\"], \"Metric\": [], \"OtherScientificTerm\": [\"prior information\", \"inherent uncertainty of the estimation procedure\", \"theoretical predictions\", \"sampling process\"], \"Task\": [\"geometric estimation problems\", \"robust estimation\", \"randomized model verification\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nIn this work, we present a technique for robust estimation, which by explicitly incorporating the inherent uncertainty of the estimation procedure, results in a more efficient robust estimation algorithm. In addition, we build on recent work in randomized model verification, and use this to characterize the ` non-randomness ' of a solution. The combination of these two strategies results in a robust estimation procedure that provides a significant speed-up over existing RANSAC techniques, while requiring no prior information to guide the sampling process. In particular, our algorithm requires, on average, 3-10 times fewer samples than standard RANSAC, which is in close agreement with theoretical predictions. The efficiency of the algorithm is demonstrated on a selection of geometric estimation problems.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"robust estimation\", \"geometric estimation problems\"], \"Method\": [\"robust estimation algorithm\", \"randomized model verification\", \"RANSAC techniques\"], \"Metric\": [\"theoretical predictions\"], \"OtherScientificTerm\": [\"non-randomness\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [\"robust estimation\", \"geometric estimation problems\"], \"Method\": [\"robust estimation algorithm\", \"randomized model verification\", \"RANSAC techniques\"], \"Metric\": [\"theoretical predictions\"], \"OtherScientificTerm\": [\"non-randomness\"], \"Generic\": []}"], "doc_hash": "4020b733b178fac9038461cf299202060b92f1b024a3acbd683b0cdfb0509649", "prompt_hash": "f77776551b7ab67b1beef4804e950853a794d95f5e5d2b103c4428a488b19772", "target_hash": "6f14baa1ff62b9d16031727ca22f6391b61f50327fa66e0bfde83254204498cc", "bypass": null}
{"doc_id": 46, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAn attempt has been made to use an Augmented Transition Network as a procedural dialog model. The development of such a model appears to be important in several respects: as a device to represent and to use different dialog schemata proposed in empirical conversation analysis; as a device to represent and to use models of verbal interaction; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs. A standard ATN should be further developed in order to account for the verbal interactions of task-oriented dialogs.", "output": "{\"Generic\": [\"models\"], \"Material\": [\"task-oriented and goal-directed dialogs\", \"task-oriented dialogs\"], \"Method\": [\"conversation analysis\", \"dialog model\", \"Augmented Transition Network\"], \"Metric\": [], \"OtherScientificTerm\": [\"dialog schemata\", \"verbal interaction\"], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:6"}, "target": "{\"Generic\": [\"models\"], \"Material\": [\"task-oriented and goal-directed dialogs\", \"task-oriented dialogs\"], \"Method\": [\"conversation analysis\", \"dialog model\", \"Augmented Transition Network\"], \"Metric\": [], \"OtherScientificTerm\": [\"dialog schemata\", \"verbal interaction\"], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nAn attempt has been made to use an Augmented Transition Network as a procedural dialog model. The development of such a model appears to be important in several respects: as a device to represent and to use different dialog schemata proposed in empirical conversation analysis; as a device to represent and to use models of verbal interaction; as a device combining knowledge about dialog schemata and about verbal interaction with knowledge about task-oriented and goal-directed dialogs. A standard ATN should be further developed in order to account for the verbal interactions of task-oriented dialogs.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [\"Augmented Transition Network\", \"ATN\"], \"Material\": [], \"OtherScientificTerm\": [\"dialog schemata\", \"verbal interaction\", \"task-oriented and goal-directed dialogs\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [\"Augmented Transition Network\", \"ATN\"], \"Material\": [], \"OtherScientificTerm\": [\"dialog schemata\", \"verbal interaction\", \"task-oriented and goal-directed dialogs\"], \"Generic\": []}"], "doc_hash": "2532ba4977fe7e9df4fc278ba24392e57b4149ce4a6ad118481d9d18615939b8", "prompt_hash": "37ef7e8cf603f1c375b5b3f2bad7ce9b9ef85fef3b849e5fa5ea2f6f7c972726", "target_hash": "cf268a1c3536fec7542c6bc6782c33a21f95ce98b30648073deca689cdcb0f11", "bypass": null}
{"doc_id": 47, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines. The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples, which are then used to train an svm to separate the two classes. We show experimentally that the proposed method is viable, that it outperforms the alternative of training the system on questions and news articles from trec, and that it helps the search engine handle definition questions significantly better.", "output": "{\"Generic\": [\"alternative\"], \"Material\": [\"news articles\", \"positive and negative definition examples\", \"on-line encyclopedias and dictionaries\", \"trec\"], \"Method\": [\"Web search engines\", \"question answering systems\", \"unsupervised learning method\", \"svm\"], \"Metric\": [], \"OtherScientificTerm\": [\"single-snippet answers\"], \"Task\": []}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:7"}, "target": "{\"Generic\": [\"alternative\"], \"Material\": [\"news articles\", \"positive and negative definition examples\", \"on-line encyclopedias and dictionaries\", \"trec\"], \"Method\": [\"Web search engines\", \"question answering systems\", \"unsupervised learning method\", \"svm\"], \"Metric\": [], \"OtherScientificTerm\": [\"single-snippet answers\"], \"Task\": []}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe present a practically unsupervised learning method to produce single-snippet answers to definition questions in question answering systems that supplement Web search engines. The method exploits on-line encyclopedias and dictionaries to generate automatically an arbitrarily large number of positive and negative definition examples, which are then used to train an svm to separate the two classes. We show experimentally that the proposed method is viable, that it outperforms the alternative of training the system on questions and news articles from trec, and that it helps the search engine handle definition questions significantly better.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [\"question answering systems\", \"definition questions\"], \"Method\": [\"svm\", \"on-line encyclopedias and dictionaries\"], \"Material\": [\"Web search engines\", \"questions and news articles from trec\"], \"OtherScientificTerm\": [\"definition examples\", \"positive and negative definition examples\"]}"]], "filtered_resps": ["{\"Task\": [\"question answering systems\", \"definition questions\"], \"Method\": [\"svm\", \"on-line encyclopedias and dictionaries\"], \"Material\": [\"Web search engines\", \"questions and news articles from trec\"], \"OtherScientificTerm\": [\"definition examples\", \"positive and negative definition examples\"]}"], "doc_hash": "ce1bfc0a469a340605805d90141bf1c0996f5a086121bcecbc1c2b04b1e5f48c", "prompt_hash": "f47308738d9ae34d90f89cfbd79004ab163fc6a88935b59a1ab3c44e3f66f7b1", "target_hash": "e992655f76303cbdd85fa2d91079ed6bb76cb34c3669ba34c6f8d48570be98ad", "bypass": null}
{"doc_id": 48, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"Bayesian analyses\", \"statistical learning perspective\", \"sharp error estimates\"], \"Metric\": [], \"OtherScientificTerm\": [\"Nitzan-Paroush weighted majority\", \"expert competence levels\", \"competence levels\", \"optimal rule\"], \"Task\": [\"classical decision-theoretic problem of weighted expert voting\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:8"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"Bayesian analyses\", \"statistical learning perspective\", \"sharp error estimates\"], \"Metric\": [], \"OtherScientificTerm\": [\"Nitzan-Paroush weighted majority\", \"expert competence levels\", \"competence levels\", \"optimal rule\"], \"Task\": [\"classical decision-theoretic problem of weighted expert voting\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"optimal Nitzan-Paroush weighted majority\", \"competence levels\", \"error estimates\", \"frequentist and Bayesian analyses\", \"proof techniques\", \"bounds\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"optimal Nitzan-Paroush weighted majority\", \"competence levels\", \"error estimates\", \"frequentist and Bayesian analyses\", \"proof techniques\", \"bounds\"], \"Generic\": []}"], "doc_hash": "79c0becc3bb7dd271caad9703200e2c0444ec6b7ff9232b0cda5148b60ee4fc6", "prompt_hash": "05a4b18daab24cc9a1cbcf943ea7bc9dbde499837fff790855b0e4726a1d50d6", "target_hash": "b39bd807ec2f606bfaddcfcc92939574712de7498b2c55c8333f7434363f4edc", "bypass": null}
{"doc_id": 49, "doc": {"input": "You will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph. We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion, and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges. When the region graph has two layers, corresponding to a Bethe approximation, we show that our sufficient conditions for concavity are also necessary. Finally, we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph. We conclude with simulations that demonstrate the advantages of the reweighted Kikuchi approach.", "output": "{\"Generic\": [], \"Material\": [], \"Method\": [\"Kikuchi approximation\", \"reweighted version of the Kikuchi approximation\", \"reweighted version of the sum product algorithm\", \"Bethe approximation\"], \"Metric\": [], \"OtherScientificTerm\": [\"cycle structure\", \"region graph\", \"Kikuchi region graph\", \"global optima\", \"Kikuchi expansion\", \"weight assignments\", \"concavity\", \"reweighted objective function\"], \"Task\": [\"log partition function of a product distribution\"]}", "metadata": {"domains": ["artificial_intelligence"], "input_context": "paragraph", "output_context": "json", "source_type": "single_source", "task_family": "ie.named_entity_recognition"}, "_instance_id": "scierc_ner:validation:9"}, "target": "{\"Generic\": [], \"Material\": [], \"Method\": [\"Kikuchi approximation\", \"reweighted version of the Kikuchi approximation\", \"reweighted version of the sum product algorithm\", \"Bethe approximation\"], \"Metric\": [], \"OtherScientificTerm\": [\"cycle structure\", \"region graph\", \"Kikuchi region graph\", \"global optima\", \"Kikuchi expansion\", \"weight assignments\", \"concavity\", \"reweighted objective function\"], \"Task\": [\"log partition function of a product distribution\"]}", "arguments": {"gen_args_0": {"arg_0": "<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou will be shown an abstract from a computer science research paper. Given this abstract, your task is to extract all unique entities with the following types:\n\n- \"Task\": Applications, problems to solve, systems to construct. Examples include \"information extraction\", \"machine reading system\", \"image segmentation\".\n- \"Method\": : Methods, models, systems to use, or tools, components of a system, frameworks. Examples include \"language model\", \"CORENLP\", \"POS parser\".\n- \"Metric\": Metrics, measures, or entities that can express quality of a system / method. Examples include \"F1\", \"BLEU\", \"Precision\", \"time complexity\".\n- \"Material\": Data, datasets, resources, Corpus, Knowledge base. Examples include \"image data\", \"speech data\", \"stereo images\", \"CoNLL\", \"Wikipedia\".\n- \"OtherScientificTerm\": Phrases that are a scientific terms but do not fall into any of the above classes. Examples include \"physical or geometric constraints\", \"qualitative prior knowledge\", \"tree kernel\", \"noise\".\n- \"Generic\": General terms or pronouns that may refer to a entity but are not themselves informative, often used as connection words. Examples include \"model\", \"approach\", \"them\".\n\nPlease return the output as a JSON object of the format: {\"type1\" : [\"example_entity\", ...], \"type2\" : [\"example_entity\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. Entity types with no matching entities should be assigned an empty array [].\n\nFor instance, the output might look like: {\"Task\": [\"speech recognition\", ...], \"Method\": [\"Conditional random field\"], \"Material\": [], ...}.\n\nOnly output the JSON object and do not include any additional text.\n\nAbstract:\n\nWe analyze a reweighted version of the Kikuchi approximation for estimating the log partition function of a product distribution defined over a region graph. We establish sufficient conditions for the concavity of our reweighted objective function in terms of weight assignments in the Kikuchi expansion, and show that a reweighted version of the sum product algorithm applied to the Kikuchi region graph will produce global optima of the Kikuchi approximation whenever the algorithm converges. When the region graph has two layers, corresponding to a Bethe approximation, we show that our sufficient conditions for concavity are also necessary. Finally, we provide an explicit characterization of the polytope of concavity in terms of the cycle structure of the region graph. We conclude with simulations that demonstrate the advantages of the reweighted Kikuchi approach.<|im_end|>\n<|im_start|>assistant\n", "arg_1": {"until": ["\n\n--------------------\n\n"], "do_sample": false, "max_gen_toks": 1024}}}, "resps": [["{\"Task\": [], \"Method\": [\"Kikuchi approximation\", \"reweighted objective function\", \"sum product algorithm\", \"Kikuchi region graph\", \"Bethe approximation\", \"polytope of concavity\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"log partition function\", \"region graph\", \"weight assignments\", \"Kikuchi expansion\", \"global optima\", \"cycle structure\"], \"Generic\": []}"]], "filtered_resps": ["{\"Task\": [], \"Method\": [\"Kikuchi approximation\", \"reweighted objective function\", \"sum product algorithm\", \"Kikuchi region graph\", \"Bethe approximation\", \"polytope of concavity\"], \"Metric\": [], \"Material\": [], \"OtherScientificTerm\": [\"log partition function\", \"region graph\", \"weight assignments\", \"Kikuchi expansion\", \"global optima\", \"cycle structure\"], \"Generic\": []}"], "doc_hash": "b27262d45bc72b2735f37eb64804493bc3c907345a73e2e92bebb0fb50a7a8bd", "prompt_hash": "8ad9926bc32eac375b27dc9a11b691b1797608abd6531900672f8eba418e61d6", "target_hash": "d9e2d0f65159f5de321e06a4e372a2424ee716867b3c027e98ea75a89ad86ad8", "bypass": null}
